{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 \n",
    "\n",
    "### 1. Non negative matrix factorization (NMF)\n",
    "\n",
    "If you have worked or are working with recommendation algorithms, I'd say you are very familiar with matrix factorization. Just in case let's go quickly through some formulation before jumping into the code. \n",
    "\n",
    "Given a ratings (or scores) matrix $R$ with dimensions $M \\times N$ we aim to find two matrix $C$ and $U$ with dimensions $M \\times K$ and $N \\times K$ respectively such that\n",
    "\n",
    "$R \\approx C \\times U^T = \\hat{R}$\n",
    "\n",
    "$K$ are the latent factors (or latent dimensions) which we will choose at our convenience. Then the rating of item $i$ by user $i$ can be computed as the dot product \n",
    "\n",
    "$ \\hat{r}_{ij} = c_i u_j^T = \\sum_{k=1}^k{c_{ik}u_{kj}}$\n",
    "\n",
    "\n",
    "In our case, $R$, $C$ and $U$ are our interest, coupons and user matrices respectively. Since we have no measure of negative interest, all matrices will be non-negative and hence non-negative matrix factorization. You can find a nice tutorial in python [here](http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/).\n",
    "\n",
    "Once we have computed $\\hat{R}$ we will be in a position where we can recommend existing coupons to customers based on past interactions. **However** let's emphasize once more that this is **NOT** the problem we are solving here. Here we have a bacth of new, unseen coupons and we need to recommend them to existing customers. In this context, there are two ways of forward. \n",
    "\n",
    "**Approach 1**\n",
    "1. Compute $\\hat{R}$ and $C$ and $U$\n",
    "2. Compute similarity between new and old (new --> old) coupons based on features (price, category, etc)\n",
    "3. Recommend and rank based on $\\hat{R}$\n",
    "4. Map old to new coupons based on previously computed similarity (old --> new)\n",
    "5. Compute MAP\n",
    "\n",
    "This approach is very similar to the one described in Chapter 9. As we know, the forward and backwards mapping is computationally expensive.\n",
    "\n",
    "and \n",
    "\n",
    "**Approach 2**\n",
    "1. Compute $\\hat{R}$ and $C$ and $U$\n",
    "2. Compute similarity between new and old (new --> old) coupons based on features (price, category, etc), and assign the latent factors of the old coupons to the most similar new coupons. \n",
    "3. Build a dataset horizontally stacking user and item latent factors.\n",
    "4. Use a regressor to predict interest and rank. \n",
    "5. Compute MAP\n",
    "\n",
    "This second approach involves one one mapping step and uses both users and coupons latent factors. Therefore, we will use this approach here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from recutils.average_precision import mapk\n",
    "from recutils.utils import coupon_similarity_function\n",
    "\n",
    "\n",
    "inp_dir = \"../datasets/Ponpare/data_processed/\"\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validation coupons\n",
    "df_coupons_train_feat = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_coupons_train_feat.p'))\n",
    "df_coupons_valid_feat = pd.read_pickle(os.path.join(inp_dir, valid_dir, 'df_coupons_valid_feat.p'))\n",
    "\n",
    "# train and validation coupon ids\n",
    "coupons_train_ids = df_coupons_train_feat.coupon_id_hash.values\n",
    "coupons_valid_ids = df_coupons_valid_feat.coupon_id_hash.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `recutils` module there is a submodule simply called `utils` that contains the `coupon_similarity_function` method. All the code in this function is shown in previous chapters. For convenience I decided to wrap it up in a method and use it here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jrz/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# validation to train coupon similarity\n",
    "train_coupons_path = os.path.join(inp_dir, train_dir, 'df_coupons_train_feat.p')\n",
    "valid_coupons_path = os.path.join(inp_dir, valid_dir, 'df_coupons_valid_feat.p')\n",
    "\n",
    "valid_to_train_most_similar = coupon_similarity_function(train_coupons_path, valid_coupons_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the most similar training coupon to the validation coupon `f1540e7a08cce1a8d5a5ebd8233e1db0` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bac9eefb777645cdc30eec34a9a4fe1f'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_to_train_most_similar['f1540e7a08cce1a8d5a5ebd8233e1db0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat</th>\n",
       "      <th>usable_date_tue_cat</th>\n",
       "      <th>usable_date_wed_cat</th>\n",
       "      <th>usable_date_thu_cat</th>\n",
       "      <th>usable_date_fri_cat</th>\n",
       "      <th>usable_date_sat_cat</th>\n",
       "      <th>usable_date_sun_cat</th>\n",
       "      <th>usable_date_holiday_cat</th>\n",
       "      <th>usable_date_before_holiday_cat</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>validperiod_method1_cat</th>\n",
       "      <th>validperiod_method2_cat</th>\n",
       "      <th>validfrom_method1_cat</th>\n",
       "      <th>validfrom_method2_cat</th>\n",
       "      <th>validend_method1_cat</th>\n",
       "      <th>validend_method2_cat</th>\n",
       "      <th>dispfrom_cat</th>\n",
       "      <th>dispend_cat</th>\n",
       "      <th>dispperiod_cat</th>\n",
       "      <th>price_rate_cat</th>\n",
       "      <th>catalog_price_cat</th>\n",
       "      <th>discount_price_cat</th>\n",
       "      <th>capsule_text_cat</th>\n",
       "      <th>genre_name_cat</th>\n",
       "      <th>large_area_name_cat</th>\n",
       "      <th>ken_name_cat</th>\n",
       "      <th>small_area_name_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17478</th>\n",
       "      <td>62</td>\n",
       "      <td>3190</td>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>bac9eefb777645cdc30eec34a9a4fe1f</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price_rate  catalog_price  discount_price  dispperiod  validperiod  \\\n",
       "17478          62           3190            1200           3           16   \n",
       "\n",
       "       usable_date_mon_cat  usable_date_tue_cat  usable_date_wed_cat  \\\n",
       "17478                    3                    3                    3   \n",
       "\n",
       "       usable_date_thu_cat  usable_date_fri_cat  usable_date_sat_cat  \\\n",
       "17478                    3                    3                    3   \n",
       "\n",
       "       usable_date_sun_cat  usable_date_holiday_cat  \\\n",
       "17478                    3                        3   \n",
       "\n",
       "       usable_date_before_holiday_cat                    coupon_id_hash  \\\n",
       "17478                               3  bac9eefb777645cdc30eec34a9a4fe1f   \n",
       "\n",
       "      validperiod_method1_cat validperiod_method2_cat  validfrom_method1_cat  \\\n",
       "17478                       4                       0                      7   \n",
       "\n",
       "       validfrom_method2_cat  validend_method1_cat  validend_method2_cat  \\\n",
       "17478                      3                     7                     5   \n",
       "\n",
       "       dispfrom_cat  dispend_cat dispperiod_cat price_rate_cat  \\\n",
       "17478             1            4              1              2   \n",
       "\n",
       "      catalog_price_cat discount_price_cat  capsule_text_cat  genre_name_cat  \\\n",
       "17478                 0                  0                 6               6   \n",
       "\n",
       "       large_area_name_cat  ken_name_cat  small_area_name_cat  \n",
       "17478                    0             2                    5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coupons_train_feat[df_coupons_train_feat.coupon_id_hash == 'bac9eefb777645cdc30eec34a9a4fe1f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat</th>\n",
       "      <th>usable_date_tue_cat</th>\n",
       "      <th>usable_date_wed_cat</th>\n",
       "      <th>usable_date_thu_cat</th>\n",
       "      <th>usable_date_fri_cat</th>\n",
       "      <th>usable_date_sat_cat</th>\n",
       "      <th>usable_date_sun_cat</th>\n",
       "      <th>usable_date_holiday_cat</th>\n",
       "      <th>usable_date_before_holiday_cat</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>validperiod_method1_cat</th>\n",
       "      <th>validperiod_method2_cat</th>\n",
       "      <th>validfrom_method1_cat</th>\n",
       "      <th>validfrom_method2_cat</th>\n",
       "      <th>validend_method1_cat</th>\n",
       "      <th>validend_method2_cat</th>\n",
       "      <th>dispfrom_cat</th>\n",
       "      <th>dispend_cat</th>\n",
       "      <th>dispperiod_cat</th>\n",
       "      <th>price_rate_cat</th>\n",
       "      <th>catalog_price_cat</th>\n",
       "      <th>discount_price_cat</th>\n",
       "      <th>capsule_text_cat</th>\n",
       "      <th>genre_name_cat</th>\n",
       "      <th>large_area_name_cat</th>\n",
       "      <th>ken_name_cat</th>\n",
       "      <th>small_area_name_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>55</td>\n",
       "      <td>2200</td>\n",
       "      <td>980</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>f1540e7a08cce1a8d5a5ebd8233e1db0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price_rate  catalog_price  discount_price  dispperiod  validperiod  \\\n",
       "210          55           2200             980           3           16   \n",
       "\n",
       "     usable_date_mon_cat  usable_date_tue_cat  usable_date_wed_cat  \\\n",
       "210                    3                    3                    3   \n",
       "\n",
       "     usable_date_thu_cat  usable_date_fri_cat  usable_date_sat_cat  \\\n",
       "210                    3                    3                    3   \n",
       "\n",
       "     usable_date_sun_cat  usable_date_holiday_cat  \\\n",
       "210                    3                        3   \n",
       "\n",
       "     usable_date_before_holiday_cat                    coupon_id_hash  \\\n",
       "210                               3  f1540e7a08cce1a8d5a5ebd8233e1db0   \n",
       "\n",
       "    validperiod_method1_cat validperiod_method2_cat  validfrom_method1_cat  \\\n",
       "210                       4                       0                      7   \n",
       "\n",
       "     validfrom_method2_cat  validend_method1_cat  validend_method2_cat  \\\n",
       "210                      3                     7                     2   \n",
       "\n",
       "     dispfrom_cat  dispend_cat dispperiod_cat price_rate_cat  \\\n",
       "210             1            4              1              1   \n",
       "\n",
       "    catalog_price_cat discount_price_cat  capsule_text_cat  genre_name_cat  \\\n",
       "210                 0                  0                 6               6   \n",
       "\n",
       "     large_area_name_cat  ken_name_cat  small_area_name_cat  \n",
       "210                    0             2                    5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coupons_valid_feat[df_coupons_valid_feat.coupon_id_hash == \"f1540e7a08cce1a8d5a5ebd8233e1db0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, very similar. \n",
    "\n",
    "Let's now load the interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22623x18622 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1560464 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's load the activity matrix and dict of indexes\n",
    "interactions_mtx = load_npz(os.path.join(inp_dir, train_dir, \"interactions_mtx.npz\"))\n",
    "items_idx_dict = pickle.load(open(os.path.join(inp_dir, train_dir, \"items_idx_dict.p\"),'rb'))\n",
    "users_idx_dict = pickle.load(open(os.path.join(inp_dir, train_dir, \"users_idx_dict.p\"),'rb'))\n",
    "interactions_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None negative matrix factorization with default values and 100 components/factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 100\n",
    "nmf_model = NMF(n_components=n_comp, init='random', random_state=1981)\n",
    "user_factors = nmf_model.fit_transform(interactions_mtx)\n",
    "item_factors = nmf_model.components_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that we have our item and user projections onto our latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22623, 100)\n",
      "(18622, 100)\n"
     ]
    }
   ],
   "source": [
    "print(user_factors.shape)\n",
    "print(item_factors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure every user/item points to the right latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure every user/item points to the right factors\n",
    "user_factors_dict = {}\n",
    "for k,v in users_idx_dict.items():\n",
    "    user_factors_dict[k] = user_factors[users_idx_dict[k]]\n",
    "\n",
    "item_factors_dict = {}\n",
    "for k,v in items_idx_dict.items():\n",
    "    item_factors_dict[k] = item_factors[items_idx_dict[k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now only thing left to do is to train a regressor, more precisely, our favourite lightGBM. Let's build the training/testing datasets and build the model. By the way, now there are no categorical features, and our life is just a bit esier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560464, 203)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interest = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_interest.p'))\n",
    "df_user_factors = (pd.DataFrame.from_dict(user_factors_dict, orient=\"index\")\n",
    "    .reset_index())\n",
    "df_user_factors.columns = ['user_id_hash'] + ['user_factor_'+str(i) for i in range(n_comp)]\n",
    "df_item_factors = (pd.DataFrame.from_dict(item_factors_dict, orient=\"index\")\n",
    "    .reset_index())\n",
    "df_item_factors.columns = ['coupon_id_hash'] + ['item_factor_'+str(i) for i in range(n_comp)]\n",
    "df_train = pd.merge(df_interest[['user_id_hash','coupon_id_hash','interest']],\n",
    "    df_item_factors, on='coupon_id_hash')\n",
    "df_train = pd.merge(df_train, df_user_factors, on='user_id_hash')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.iloc[:,3:].values\n",
    "y = df_train.interest.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.27389\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's rmse: 0.272165\n",
      "[3]\tvalid_0's rmse: 0.270627\n",
      "[4]\tvalid_0's rmse: 0.269388\n",
      "[5]\tvalid_0's rmse: 0.268348\n",
      "[6]\tvalid_0's rmse: 0.267333\n",
      "[7]\tvalid_0's rmse: 0.266564\n",
      "[8]\tvalid_0's rmse: 0.265698\n",
      "[9]\tvalid_0's rmse: 0.265071\n",
      "[10]\tvalid_0's rmse: 0.26431\n",
      "[11]\tvalid_0's rmse: 0.263691\n",
      "[12]\tvalid_0's rmse: 0.263187\n",
      "[13]\tvalid_0's rmse: 0.262618\n",
      "[14]\tvalid_0's rmse: 0.262151\n",
      "[15]\tvalid_0's rmse: 0.261611\n",
      "[16]\tvalid_0's rmse: 0.261167\n",
      "[17]\tvalid_0's rmse: 0.260688\n",
      "[18]\tvalid_0's rmse: 0.260246\n",
      "[19]\tvalid_0's rmse: 0.259751\n",
      "[20]\tvalid_0's rmse: 0.259429\n",
      "[21]\tvalid_0's rmse: 0.259055\n",
      "[22]\tvalid_0's rmse: 0.25864\n",
      "[23]\tvalid_0's rmse: 0.258305\n",
      "[24]\tvalid_0's rmse: 0.257903\n",
      "[25]\tvalid_0's rmse: 0.257538\n",
      "[26]\tvalid_0's rmse: 0.257163\n",
      "[27]\tvalid_0's rmse: 0.25685\n",
      "[28]\tvalid_0's rmse: 0.256529\n",
      "[29]\tvalid_0's rmse: 0.256221\n",
      "[30]\tvalid_0's rmse: 0.255909\n",
      "[31]\tvalid_0's rmse: 0.255589\n",
      "[32]\tvalid_0's rmse: 0.255283\n",
      "[33]\tvalid_0's rmse: 0.254947\n",
      "[34]\tvalid_0's rmse: 0.254609\n",
      "[35]\tvalid_0's rmse: 0.254363\n",
      "[36]\tvalid_0's rmse: 0.254057\n",
      "[37]\tvalid_0's rmse: 0.253823\n",
      "[38]\tvalid_0's rmse: 0.253559\n",
      "[39]\tvalid_0's rmse: 0.253271\n",
      "[40]\tvalid_0's rmse: 0.253\n",
      "[41]\tvalid_0's rmse: 0.252689\n",
      "[42]\tvalid_0's rmse: 0.252396\n",
      "[43]\tvalid_0's rmse: 0.252198\n",
      "[44]\tvalid_0's rmse: 0.25202\n",
      "[45]\tvalid_0's rmse: 0.251747\n",
      "[46]\tvalid_0's rmse: 0.251448\n",
      "[47]\tvalid_0's rmse: 0.251197\n",
      "[48]\tvalid_0's rmse: 0.250906\n",
      "[49]\tvalid_0's rmse: 0.25063\n",
      "[50]\tvalid_0's rmse: 0.250419\n",
      "[51]\tvalid_0's rmse: 0.250166\n",
      "[52]\tvalid_0's rmse: 0.249851\n",
      "[53]\tvalid_0's rmse: 0.249575\n",
      "[54]\tvalid_0's rmse: 0.249287\n",
      "[55]\tvalid_0's rmse: 0.249075\n",
      "[56]\tvalid_0's rmse: 0.248909\n",
      "[57]\tvalid_0's rmse: 0.248717\n",
      "[58]\tvalid_0's rmse: 0.248549\n",
      "[59]\tvalid_0's rmse: 0.248333\n",
      "[60]\tvalid_0's rmse: 0.248123\n",
      "[61]\tvalid_0's rmse: 0.247933\n",
      "[62]\tvalid_0's rmse: 0.247713\n",
      "[63]\tvalid_0's rmse: 0.247519\n",
      "[64]\tvalid_0's rmse: 0.247314\n",
      "[65]\tvalid_0's rmse: 0.247122\n",
      "[66]\tvalid_0's rmse: 0.246907\n",
      "[67]\tvalid_0's rmse: 0.246724\n",
      "[68]\tvalid_0's rmse: 0.246526\n",
      "[69]\tvalid_0's rmse: 0.246343\n",
      "[70]\tvalid_0's rmse: 0.246167\n",
      "[71]\tvalid_0's rmse: 0.245988\n",
      "[72]\tvalid_0's rmse: 0.245848\n",
      "[73]\tvalid_0's rmse: 0.245631\n",
      "[74]\tvalid_0's rmse: 0.24546\n",
      "[75]\tvalid_0's rmse: 0.245273\n",
      "[76]\tvalid_0's rmse: 0.245067\n",
      "[77]\tvalid_0's rmse: 0.244905\n",
      "[78]\tvalid_0's rmse: 0.244707\n",
      "[79]\tvalid_0's rmse: 0.244514\n",
      "[80]\tvalid_0's rmse: 0.244339\n",
      "[81]\tvalid_0's rmse: 0.24419\n",
      "[82]\tvalid_0's rmse: 0.244033\n",
      "[83]\tvalid_0's rmse: 0.243885\n",
      "[84]\tvalid_0's rmse: 0.243704\n",
      "[85]\tvalid_0's rmse: 0.243489\n",
      "[86]\tvalid_0's rmse: 0.243291\n",
      "[87]\tvalid_0's rmse: 0.243142\n",
      "[88]\tvalid_0's rmse: 0.242991\n",
      "[89]\tvalid_0's rmse: 0.242878\n",
      "[90]\tvalid_0's rmse: 0.242728\n",
      "[91]\tvalid_0's rmse: 0.242594\n",
      "[92]\tvalid_0's rmse: 0.242452\n",
      "[93]\tvalid_0's rmse: 0.24231\n",
      "[94]\tvalid_0's rmse: 0.242179\n",
      "[95]\tvalid_0's rmse: 0.242044\n",
      "[96]\tvalid_0's rmse: 0.241901\n",
      "[97]\tvalid_0's rmse: 0.24175\n",
      "[98]\tvalid_0's rmse: 0.241601\n",
      "[99]\tvalid_0's rmse: 0.241467\n",
      "[100]\tvalid_0's rmse: 0.241331\n",
      "[101]\tvalid_0's rmse: 0.24114\n",
      "[102]\tvalid_0's rmse: 0.241025\n",
      "[103]\tvalid_0's rmse: 0.240877\n",
      "[104]\tvalid_0's rmse: 0.240758\n",
      "[105]\tvalid_0's rmse: 0.240619\n",
      "[106]\tvalid_0's rmse: 0.24051\n",
      "[107]\tvalid_0's rmse: 0.240364\n",
      "[108]\tvalid_0's rmse: 0.240226\n",
      "[109]\tvalid_0's rmse: 0.240094\n",
      "[110]\tvalid_0's rmse: 0.239941\n",
      "[111]\tvalid_0's rmse: 0.239808\n",
      "[112]\tvalid_0's rmse: 0.239697\n",
      "[113]\tvalid_0's rmse: 0.239549\n",
      "[114]\tvalid_0's rmse: 0.239428\n",
      "[115]\tvalid_0's rmse: 0.239328\n",
      "[116]\tvalid_0's rmse: 0.239184\n",
      "[117]\tvalid_0's rmse: 0.239063\n",
      "[118]\tvalid_0's rmse: 0.238941\n",
      "[119]\tvalid_0's rmse: 0.238832\n",
      "[120]\tvalid_0's rmse: 0.238723\n",
      "[121]\tvalid_0's rmse: 0.23862\n",
      "[122]\tvalid_0's rmse: 0.238489\n",
      "[123]\tvalid_0's rmse: 0.238383\n",
      "[124]\tvalid_0's rmse: 0.238256\n",
      "[125]\tvalid_0's rmse: 0.238145\n",
      "[126]\tvalid_0's rmse: 0.238017\n",
      "[127]\tvalid_0's rmse: 0.237876\n",
      "[128]\tvalid_0's rmse: 0.237738\n",
      "[129]\tvalid_0's rmse: 0.23766\n",
      "[130]\tvalid_0's rmse: 0.23756\n",
      "[131]\tvalid_0's rmse: 0.237453\n",
      "[132]\tvalid_0's rmse: 0.237342\n",
      "[133]\tvalid_0's rmse: 0.237221\n",
      "[134]\tvalid_0's rmse: 0.237108\n",
      "[135]\tvalid_0's rmse: 0.236983\n",
      "[136]\tvalid_0's rmse: 0.236855\n",
      "[137]\tvalid_0's rmse: 0.236752\n",
      "[138]\tvalid_0's rmse: 0.236653\n",
      "[139]\tvalid_0's rmse: 0.236557\n",
      "[140]\tvalid_0's rmse: 0.236429\n",
      "[141]\tvalid_0's rmse: 0.23631\n",
      "[142]\tvalid_0's rmse: 0.236199\n",
      "[143]\tvalid_0's rmse: 0.236096\n",
      "[144]\tvalid_0's rmse: 0.236006\n",
      "[145]\tvalid_0's rmse: 0.235855\n",
      "[146]\tvalid_0's rmse: 0.235766\n",
      "[147]\tvalid_0's rmse: 0.235685\n",
      "[148]\tvalid_0's rmse: 0.235607\n",
      "[149]\tvalid_0's rmse: 0.235535\n",
      "[150]\tvalid_0's rmse: 0.235411\n",
      "[151]\tvalid_0's rmse: 0.235292\n",
      "[152]\tvalid_0's rmse: 0.235228\n",
      "[153]\tvalid_0's rmse: 0.235142\n",
      "[154]\tvalid_0's rmse: 0.235075\n",
      "[155]\tvalid_0's rmse: 0.234993\n",
      "[156]\tvalid_0's rmse: 0.234843\n",
      "[157]\tvalid_0's rmse: 0.23476\n",
      "[158]\tvalid_0's rmse: 0.234694\n",
      "[159]\tvalid_0's rmse: 0.234573\n",
      "[160]\tvalid_0's rmse: 0.234459\n",
      "[161]\tvalid_0's rmse: 0.234364\n",
      "[162]\tvalid_0's rmse: 0.23426\n",
      "[163]\tvalid_0's rmse: 0.2342\n",
      "[164]\tvalid_0's rmse: 0.234105\n",
      "[165]\tvalid_0's rmse: 0.234033\n",
      "[166]\tvalid_0's rmse: 0.233945\n",
      "[167]\tvalid_0's rmse: 0.233863\n",
      "[168]\tvalid_0's rmse: 0.23378\n",
      "[169]\tvalid_0's rmse: 0.233687\n",
      "[170]\tvalid_0's rmse: 0.233612\n",
      "[171]\tvalid_0's rmse: 0.23354\n",
      "[172]\tvalid_0's rmse: 0.233484\n",
      "[173]\tvalid_0's rmse: 0.233413\n",
      "[174]\tvalid_0's rmse: 0.233354\n",
      "[175]\tvalid_0's rmse: 0.233289\n",
      "[176]\tvalid_0's rmse: 0.233228\n",
      "[177]\tvalid_0's rmse: 0.233129\n",
      "[178]\tvalid_0's rmse: 0.23304\n",
      "[179]\tvalid_0's rmse: 0.232965\n",
      "[180]\tvalid_0's rmse: 0.232881\n",
      "[181]\tvalid_0's rmse: 0.232803\n",
      "[182]\tvalid_0's rmse: 0.232697\n",
      "[183]\tvalid_0's rmse: 0.232616\n",
      "[184]\tvalid_0's rmse: 0.232535\n",
      "[185]\tvalid_0's rmse: 0.232432\n",
      "[186]\tvalid_0's rmse: 0.232382\n",
      "[187]\tvalid_0's rmse: 0.232305\n",
      "[188]\tvalid_0's rmse: 0.232245\n",
      "[189]\tvalid_0's rmse: 0.232146\n",
      "[190]\tvalid_0's rmse: 0.232065\n",
      "[191]\tvalid_0's rmse: 0.231961\n",
      "[192]\tvalid_0's rmse: 0.231907\n",
      "[193]\tvalid_0's rmse: 0.231833\n",
      "[194]\tvalid_0's rmse: 0.231795\n",
      "[195]\tvalid_0's rmse: 0.231732\n",
      "[196]\tvalid_0's rmse: 0.231688\n",
      "[197]\tvalid_0's rmse: 0.231612\n",
      "[198]\tvalid_0's rmse: 0.231516\n",
      "[199]\tvalid_0's rmse: 0.231411\n",
      "[200]\tvalid_0's rmse: 0.231322\n",
      "[201]\tvalid_0's rmse: 0.231238\n",
      "[202]\tvalid_0's rmse: 0.231177\n",
      "[203]\tvalid_0's rmse: 0.231118\n",
      "[204]\tvalid_0's rmse: 0.231066\n",
      "[205]\tvalid_0's rmse: 0.230971\n",
      "[206]\tvalid_0's rmse: 0.230919\n",
      "[207]\tvalid_0's rmse: 0.230871\n",
      "[208]\tvalid_0's rmse: 0.230807\n",
      "[209]\tvalid_0's rmse: 0.230747\n",
      "[210]\tvalid_0's rmse: 0.230698\n",
      "[211]\tvalid_0's rmse: 0.230625\n",
      "[212]\tvalid_0's rmse: 0.230586\n",
      "[213]\tvalid_0's rmse: 0.230534\n",
      "[214]\tvalid_0's rmse: 0.23047\n",
      "[215]\tvalid_0's rmse: 0.23042\n",
      "[216]\tvalid_0's rmse: 0.230373\n",
      "[217]\tvalid_0's rmse: 0.230316\n",
      "[218]\tvalid_0's rmse: 0.230263\n",
      "[219]\tvalid_0's rmse: 0.230214\n",
      "[220]\tvalid_0's rmse: 0.230145\n",
      "[221]\tvalid_0's rmse: 0.230081\n",
      "[222]\tvalid_0's rmse: 0.230013\n",
      "[223]\tvalid_0's rmse: 0.229949\n",
      "[224]\tvalid_0's rmse: 0.229866\n",
      "[225]\tvalid_0's rmse: 0.22981\n",
      "[226]\tvalid_0's rmse: 0.229755\n",
      "[227]\tvalid_0's rmse: 0.229694\n",
      "[228]\tvalid_0's rmse: 0.229609\n",
      "[229]\tvalid_0's rmse: 0.229538\n",
      "[230]\tvalid_0's rmse: 0.229467\n",
      "[231]\tvalid_0's rmse: 0.229404\n",
      "[232]\tvalid_0's rmse: 0.229351\n",
      "[233]\tvalid_0's rmse: 0.229283\n",
      "[234]\tvalid_0's rmse: 0.229202\n",
      "[235]\tvalid_0's rmse: 0.229147\n",
      "[236]\tvalid_0's rmse: 0.229082\n",
      "[237]\tvalid_0's rmse: 0.229019\n",
      "[238]\tvalid_0's rmse: 0.22894\n",
      "[239]\tvalid_0's rmse: 0.22888\n",
      "[240]\tvalid_0's rmse: 0.228844\n",
      "[241]\tvalid_0's rmse: 0.22878\n",
      "[242]\tvalid_0's rmse: 0.228723\n",
      "[243]\tvalid_0's rmse: 0.228693\n",
      "[244]\tvalid_0's rmse: 0.228628\n",
      "[245]\tvalid_0's rmse: 0.228569\n",
      "[246]\tvalid_0's rmse: 0.228518\n",
      "[247]\tvalid_0's rmse: 0.228477\n",
      "[248]\tvalid_0's rmse: 0.228418\n",
      "[249]\tvalid_0's rmse: 0.228364\n",
      "[250]\tvalid_0's rmse: 0.228305\n",
      "[251]\tvalid_0's rmse: 0.228253\n",
      "[252]\tvalid_0's rmse: 0.228191\n",
      "[253]\tvalid_0's rmse: 0.228142\n",
      "[254]\tvalid_0's rmse: 0.228097\n",
      "[255]\tvalid_0's rmse: 0.228056\n",
      "[256]\tvalid_0's rmse: 0.228006\n",
      "[257]\tvalid_0's rmse: 0.227973\n",
      "[258]\tvalid_0's rmse: 0.227946\n",
      "[259]\tvalid_0's rmse: 0.2279\n",
      "[260]\tvalid_0's rmse: 0.227862\n",
      "[261]\tvalid_0's rmse: 0.2278\n",
      "[262]\tvalid_0's rmse: 0.227747\n",
      "[263]\tvalid_0's rmse: 0.227702\n",
      "[264]\tvalid_0's rmse: 0.227648\n",
      "[265]\tvalid_0's rmse: 0.2276\n",
      "[266]\tvalid_0's rmse: 0.227531\n",
      "[267]\tvalid_0's rmse: 0.227503\n",
      "[268]\tvalid_0's rmse: 0.227475\n",
      "[269]\tvalid_0's rmse: 0.227428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270]\tvalid_0's rmse: 0.227396\n",
      "[271]\tvalid_0's rmse: 0.227349\n",
      "[272]\tvalid_0's rmse: 0.227293\n",
      "[273]\tvalid_0's rmse: 0.227267\n",
      "[274]\tvalid_0's rmse: 0.227221\n",
      "[275]\tvalid_0's rmse: 0.227174\n",
      "[276]\tvalid_0's rmse: 0.227116\n",
      "[277]\tvalid_0's rmse: 0.227078\n",
      "[278]\tvalid_0's rmse: 0.227049\n",
      "[279]\tvalid_0's rmse: 0.227025\n",
      "[280]\tvalid_0's rmse: 0.226972\n",
      "[281]\tvalid_0's rmse: 0.226926\n",
      "[282]\tvalid_0's rmse: 0.226889\n",
      "[283]\tvalid_0's rmse: 0.226832\n",
      "[284]\tvalid_0's rmse: 0.226818\n",
      "[285]\tvalid_0's rmse: 0.226795\n",
      "[286]\tvalid_0's rmse: 0.226757\n",
      "[287]\tvalid_0's rmse: 0.226707\n",
      "[288]\tvalid_0's rmse: 0.226643\n",
      "[289]\tvalid_0's rmse: 0.226588\n",
      "[290]\tvalid_0's rmse: 0.226539\n",
      "[291]\tvalid_0's rmse: 0.226504\n",
      "[292]\tvalid_0's rmse: 0.226468\n",
      "[293]\tvalid_0's rmse: 0.226441\n",
      "[294]\tvalid_0's rmse: 0.226378\n",
      "[295]\tvalid_0's rmse: 0.226331\n",
      "[296]\tvalid_0's rmse: 0.226295\n",
      "[297]\tvalid_0's rmse: 0.226223\n",
      "[298]\tvalid_0's rmse: 0.226187\n",
      "[299]\tvalid_0's rmse: 0.226161\n",
      "[300]\tvalid_0's rmse: 0.22612\n",
      "[301]\tvalid_0's rmse: 0.226077\n",
      "[302]\tvalid_0's rmse: 0.226046\n",
      "[303]\tvalid_0's rmse: 0.226033\n",
      "[304]\tvalid_0's rmse: 0.225991\n",
      "[305]\tvalid_0's rmse: 0.225946\n",
      "[306]\tvalid_0's rmse: 0.22592\n",
      "[307]\tvalid_0's rmse: 0.22588\n",
      "[308]\tvalid_0's rmse: 0.225826\n",
      "[309]\tvalid_0's rmse: 0.225777\n",
      "[310]\tvalid_0's rmse: 0.225716\n",
      "[311]\tvalid_0's rmse: 0.225667\n",
      "[312]\tvalid_0's rmse: 0.225607\n",
      "[313]\tvalid_0's rmse: 0.225564\n",
      "[314]\tvalid_0's rmse: 0.225521\n",
      "[315]\tvalid_0's rmse: 0.225492\n",
      "[316]\tvalid_0's rmse: 0.225444\n",
      "[317]\tvalid_0's rmse: 0.225405\n",
      "[318]\tvalid_0's rmse: 0.225372\n",
      "[319]\tvalid_0's rmse: 0.22533\n",
      "[320]\tvalid_0's rmse: 0.225287\n",
      "[321]\tvalid_0's rmse: 0.225209\n",
      "[322]\tvalid_0's rmse: 0.225189\n",
      "[323]\tvalid_0's rmse: 0.225163\n",
      "[324]\tvalid_0's rmse: 0.22513\n",
      "[325]\tvalid_0's rmse: 0.2251\n",
      "[326]\tvalid_0's rmse: 0.22507\n",
      "[327]\tvalid_0's rmse: 0.225048\n",
      "[328]\tvalid_0's rmse: 0.225012\n",
      "[329]\tvalid_0's rmse: 0.224947\n",
      "[330]\tvalid_0's rmse: 0.224897\n",
      "[331]\tvalid_0's rmse: 0.224875\n",
      "[332]\tvalid_0's rmse: 0.224779\n",
      "[333]\tvalid_0's rmse: 0.224751\n",
      "[334]\tvalid_0's rmse: 0.224721\n",
      "[335]\tvalid_0's rmse: 0.224684\n",
      "[336]\tvalid_0's rmse: 0.224666\n",
      "[337]\tvalid_0's rmse: 0.224634\n",
      "[338]\tvalid_0's rmse: 0.22461\n",
      "[339]\tvalid_0's rmse: 0.224588\n",
      "[340]\tvalid_0's rmse: 0.224546\n",
      "[341]\tvalid_0's rmse: 0.224499\n",
      "[342]\tvalid_0's rmse: 0.224477\n",
      "[343]\tvalid_0's rmse: 0.224447\n",
      "[344]\tvalid_0's rmse: 0.224402\n",
      "[345]\tvalid_0's rmse: 0.224392\n",
      "[346]\tvalid_0's rmse: 0.224304\n",
      "[347]\tvalid_0's rmse: 0.224286\n",
      "[348]\tvalid_0's rmse: 0.224245\n",
      "[349]\tvalid_0's rmse: 0.224208\n",
      "[350]\tvalid_0's rmse: 0.224155\n",
      "[351]\tvalid_0's rmse: 0.224138\n",
      "[352]\tvalid_0's rmse: 0.2241\n",
      "[353]\tvalid_0's rmse: 0.224053\n",
      "[354]\tvalid_0's rmse: 0.224035\n",
      "[355]\tvalid_0's rmse: 0.224014\n",
      "[356]\tvalid_0's rmse: 0.223966\n",
      "[357]\tvalid_0's rmse: 0.223905\n",
      "[358]\tvalid_0's rmse: 0.22388\n",
      "[359]\tvalid_0's rmse: 0.223824\n",
      "[360]\tvalid_0's rmse: 0.223812\n",
      "[361]\tvalid_0's rmse: 0.223782\n",
      "[362]\tvalid_0's rmse: 0.223763\n",
      "[363]\tvalid_0's rmse: 0.223721\n",
      "[364]\tvalid_0's rmse: 0.223694\n",
      "[365]\tvalid_0's rmse: 0.223657\n",
      "[366]\tvalid_0's rmse: 0.223632\n",
      "[367]\tvalid_0's rmse: 0.223604\n",
      "[368]\tvalid_0's rmse: 0.223569\n",
      "[369]\tvalid_0's rmse: 0.223544\n",
      "[370]\tvalid_0's rmse: 0.223515\n",
      "[371]\tvalid_0's rmse: 0.223458\n",
      "[372]\tvalid_0's rmse: 0.223418\n",
      "[373]\tvalid_0's rmse: 0.223399\n",
      "[374]\tvalid_0's rmse: 0.223375\n",
      "[375]\tvalid_0's rmse: 0.223338\n",
      "[376]\tvalid_0's rmse: 0.223309\n",
      "[377]\tvalid_0's rmse: 0.223293\n",
      "[378]\tvalid_0's rmse: 0.223279\n",
      "[379]\tvalid_0's rmse: 0.223267\n",
      "[380]\tvalid_0's rmse: 0.22324\n",
      "[381]\tvalid_0's rmse: 0.223191\n",
      "[382]\tvalid_0's rmse: 0.223166\n",
      "[383]\tvalid_0's rmse: 0.223151\n",
      "[384]\tvalid_0's rmse: 0.223129\n",
      "[385]\tvalid_0's rmse: 0.22311\n",
      "[386]\tvalid_0's rmse: 0.223077\n",
      "[387]\tvalid_0's rmse: 0.223037\n",
      "[388]\tvalid_0's rmse: 0.22298\n",
      "[389]\tvalid_0's rmse: 0.222935\n",
      "[390]\tvalid_0's rmse: 0.222914\n",
      "[391]\tvalid_0's rmse: 0.222885\n",
      "[392]\tvalid_0's rmse: 0.222804\n",
      "[393]\tvalid_0's rmse: 0.222783\n",
      "[394]\tvalid_0's rmse: 0.22277\n",
      "[395]\tvalid_0's rmse: 0.222732\n",
      "[396]\tvalid_0's rmse: 0.222702\n",
      "[397]\tvalid_0's rmse: 0.222659\n",
      "[398]\tvalid_0's rmse: 0.222643\n",
      "[399]\tvalid_0's rmse: 0.222597\n",
      "[400]\tvalid_0's rmse: 0.222559\n",
      "[401]\tvalid_0's rmse: 0.222544\n",
      "[402]\tvalid_0's rmse: 0.22249\n",
      "[403]\tvalid_0's rmse: 0.222476\n",
      "[404]\tvalid_0's rmse: 0.22242\n",
      "[405]\tvalid_0's rmse: 0.222405\n",
      "[406]\tvalid_0's rmse: 0.222396\n",
      "[407]\tvalid_0's rmse: 0.222376\n",
      "[408]\tvalid_0's rmse: 0.222334\n",
      "[409]\tvalid_0's rmse: 0.222298\n",
      "[410]\tvalid_0's rmse: 0.222279\n",
      "[411]\tvalid_0's rmse: 0.222255\n",
      "[412]\tvalid_0's rmse: 0.222244\n",
      "[413]\tvalid_0's rmse: 0.222222\n",
      "[414]\tvalid_0's rmse: 0.222197\n",
      "[415]\tvalid_0's rmse: 0.22217\n",
      "[416]\tvalid_0's rmse: 0.222117\n",
      "[417]\tvalid_0's rmse: 0.222078\n",
      "[418]\tvalid_0's rmse: 0.222027\n",
      "[419]\tvalid_0's rmse: 0.222009\n",
      "[420]\tvalid_0's rmse: 0.221991\n",
      "[421]\tvalid_0's rmse: 0.22194\n",
      "[422]\tvalid_0's rmse: 0.221925\n",
      "[423]\tvalid_0's rmse: 0.221896\n",
      "[424]\tvalid_0's rmse: 0.221865\n",
      "[425]\tvalid_0's rmse: 0.221841\n",
      "[426]\tvalid_0's rmse: 0.221834\n",
      "[427]\tvalid_0's rmse: 0.221754\n",
      "[428]\tvalid_0's rmse: 0.221723\n",
      "[429]\tvalid_0's rmse: 0.221666\n",
      "[430]\tvalid_0's rmse: 0.221649\n",
      "[431]\tvalid_0's rmse: 0.221617\n",
      "[432]\tvalid_0's rmse: 0.221599\n",
      "[433]\tvalid_0's rmse: 0.221563\n",
      "[434]\tvalid_0's rmse: 0.221552\n",
      "[435]\tvalid_0's rmse: 0.22153\n",
      "[436]\tvalid_0's rmse: 0.221512\n",
      "[437]\tvalid_0's rmse: 0.221467\n",
      "[438]\tvalid_0's rmse: 0.221451\n",
      "[439]\tvalid_0's rmse: 0.221407\n",
      "[440]\tvalid_0's rmse: 0.221399\n",
      "[441]\tvalid_0's rmse: 0.221377\n",
      "[442]\tvalid_0's rmse: 0.221371\n",
      "[443]\tvalid_0's rmse: 0.221336\n",
      "[444]\tvalid_0's rmse: 0.22131\n",
      "[445]\tvalid_0's rmse: 0.221292\n",
      "[446]\tvalid_0's rmse: 0.221277\n",
      "[447]\tvalid_0's rmse: 0.221263\n",
      "[448]\tvalid_0's rmse: 0.221228\n",
      "[449]\tvalid_0's rmse: 0.221216\n",
      "[450]\tvalid_0's rmse: 0.221179\n",
      "[451]\tvalid_0's rmse: 0.221165\n",
      "[452]\tvalid_0's rmse: 0.221127\n",
      "[453]\tvalid_0's rmse: 0.22109\n",
      "[454]\tvalid_0's rmse: 0.221055\n",
      "[455]\tvalid_0's rmse: 0.221031\n",
      "[456]\tvalid_0's rmse: 0.221019\n",
      "[457]\tvalid_0's rmse: 0.221006\n",
      "[458]\tvalid_0's rmse: 0.220997\n",
      "[459]\tvalid_0's rmse: 0.220943\n",
      "[460]\tvalid_0's rmse: 0.220907\n",
      "[461]\tvalid_0's rmse: 0.220883\n",
      "[462]\tvalid_0's rmse: 0.220845\n",
      "[463]\tvalid_0's rmse: 0.220804\n",
      "[464]\tvalid_0's rmse: 0.220772\n",
      "[465]\tvalid_0's rmse: 0.220763\n",
      "[466]\tvalid_0's rmse: 0.220727\n",
      "[467]\tvalid_0's rmse: 0.220706\n",
      "[468]\tvalid_0's rmse: 0.220686\n",
      "[469]\tvalid_0's rmse: 0.220661\n",
      "[470]\tvalid_0's rmse: 0.220631\n",
      "[471]\tvalid_0's rmse: 0.220611\n",
      "[472]\tvalid_0's rmse: 0.220594\n",
      "[473]\tvalid_0's rmse: 0.220587\n",
      "[474]\tvalid_0's rmse: 0.220555\n",
      "[475]\tvalid_0's rmse: 0.220491\n",
      "[476]\tvalid_0's rmse: 0.220468\n",
      "[477]\tvalid_0's rmse: 0.220421\n",
      "[478]\tvalid_0's rmse: 0.220391\n",
      "[479]\tvalid_0's rmse: 0.220351\n",
      "[480]\tvalid_0's rmse: 0.220313\n",
      "[481]\tvalid_0's rmse: 0.220295\n",
      "[482]\tvalid_0's rmse: 0.220266\n",
      "[483]\tvalid_0's rmse: 0.220246\n",
      "[484]\tvalid_0's rmse: 0.220225\n",
      "[485]\tvalid_0's rmse: 0.220214\n",
      "[486]\tvalid_0's rmse: 0.220194\n",
      "[487]\tvalid_0's rmse: 0.220184\n",
      "[488]\tvalid_0's rmse: 0.220163\n",
      "[489]\tvalid_0's rmse: 0.220148\n",
      "[490]\tvalid_0's rmse: 0.220119\n",
      "[491]\tvalid_0's rmse: 0.220107\n",
      "[492]\tvalid_0's rmse: 0.22009\n",
      "[493]\tvalid_0's rmse: 0.220079\n",
      "[494]\tvalid_0's rmse: 0.220061\n",
      "[495]\tvalid_0's rmse: 0.22003\n",
      "[496]\tvalid_0's rmse: 0.220014\n",
      "[497]\tvalid_0's rmse: 0.220002\n",
      "[498]\tvalid_0's rmse: 0.219994\n",
      "[499]\tvalid_0's rmse: 0.219956\n",
      "[500]\tvalid_0's rmse: 0.219918\n",
      "[501]\tvalid_0's rmse: 0.219881\n",
      "[502]\tvalid_0's rmse: 0.219859\n",
      "[503]\tvalid_0's rmse: 0.219829\n",
      "[504]\tvalid_0's rmse: 0.21978\n",
      "[505]\tvalid_0's rmse: 0.219767\n",
      "[506]\tvalid_0's rmse: 0.219749\n",
      "[507]\tvalid_0's rmse: 0.219734\n",
      "[508]\tvalid_0's rmse: 0.2197\n",
      "[509]\tvalid_0's rmse: 0.219695\n",
      "[510]\tvalid_0's rmse: 0.219653\n",
      "[511]\tvalid_0's rmse: 0.219633\n",
      "[512]\tvalid_0's rmse: 0.219596\n",
      "[513]\tvalid_0's rmse: 0.219571\n",
      "[514]\tvalid_0's rmse: 0.219528\n",
      "[515]\tvalid_0's rmse: 0.219514\n",
      "[516]\tvalid_0's rmse: 0.219498\n",
      "[517]\tvalid_0's rmse: 0.219484\n",
      "[518]\tvalid_0's rmse: 0.219477\n",
      "[519]\tvalid_0's rmse: 0.219447\n",
      "[520]\tvalid_0's rmse: 0.21944\n",
      "[521]\tvalid_0's rmse: 0.219425\n",
      "[522]\tvalid_0's rmse: 0.21941\n",
      "[523]\tvalid_0's rmse: 0.219399\n",
      "[524]\tvalid_0's rmse: 0.21937\n",
      "[525]\tvalid_0's rmse: 0.219322\n",
      "[526]\tvalid_0's rmse: 0.219287\n",
      "[527]\tvalid_0's rmse: 0.219263\n",
      "[528]\tvalid_0's rmse: 0.219245\n",
      "[529]\tvalid_0's rmse: 0.219235\n",
      "[530]\tvalid_0's rmse: 0.219216\n",
      "[531]\tvalid_0's rmse: 0.219198\n",
      "[532]\tvalid_0's rmse: 0.21916\n",
      "[533]\tvalid_0's rmse: 0.219137\n",
      "[534]\tvalid_0's rmse: 0.219124\n",
      "[535]\tvalid_0's rmse: 0.219111\n",
      "[536]\tvalid_0's rmse: 0.219109\n",
      "[537]\tvalid_0's rmse: 0.219083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[538]\tvalid_0's rmse: 0.219048\n",
      "[539]\tvalid_0's rmse: 0.219035\n",
      "[540]\tvalid_0's rmse: 0.219017\n",
      "[541]\tvalid_0's rmse: 0.218995\n",
      "[542]\tvalid_0's rmse: 0.218988\n",
      "[543]\tvalid_0's rmse: 0.218961\n",
      "[544]\tvalid_0's rmse: 0.218951\n",
      "[545]\tvalid_0's rmse: 0.218911\n",
      "[546]\tvalid_0's rmse: 0.218899\n",
      "[547]\tvalid_0's rmse: 0.21889\n",
      "[548]\tvalid_0's rmse: 0.218864\n",
      "[549]\tvalid_0's rmse: 0.218861\n",
      "[550]\tvalid_0's rmse: 0.218846\n",
      "[551]\tvalid_0's rmse: 0.218836\n",
      "[552]\tvalid_0's rmse: 0.218829\n",
      "[553]\tvalid_0's rmse: 0.218825\n",
      "[554]\tvalid_0's rmse: 0.218809\n",
      "[555]\tvalid_0's rmse: 0.218782\n",
      "[556]\tvalid_0's rmse: 0.218768\n",
      "[557]\tvalid_0's rmse: 0.218738\n",
      "[558]\tvalid_0's rmse: 0.218714\n",
      "[559]\tvalid_0's rmse: 0.218702\n",
      "[560]\tvalid_0's rmse: 0.218662\n",
      "[561]\tvalid_0's rmse: 0.218636\n",
      "[562]\tvalid_0's rmse: 0.218611\n",
      "[563]\tvalid_0's rmse: 0.218599\n",
      "[564]\tvalid_0's rmse: 0.218583\n",
      "[565]\tvalid_0's rmse: 0.218558\n",
      "[566]\tvalid_0's rmse: 0.218517\n",
      "[567]\tvalid_0's rmse: 0.2185\n",
      "[568]\tvalid_0's rmse: 0.218485\n",
      "[569]\tvalid_0's rmse: 0.218458\n",
      "[570]\tvalid_0's rmse: 0.21842\n",
      "[571]\tvalid_0's rmse: 0.218411\n",
      "[572]\tvalid_0's rmse: 0.218404\n",
      "[573]\tvalid_0's rmse: 0.218394\n",
      "[574]\tvalid_0's rmse: 0.218378\n",
      "[575]\tvalid_0's rmse: 0.218374\n",
      "[576]\tvalid_0's rmse: 0.218357\n",
      "[577]\tvalid_0's rmse: 0.218352\n",
      "[578]\tvalid_0's rmse: 0.218344\n",
      "[579]\tvalid_0's rmse: 0.21832\n",
      "[580]\tvalid_0's rmse: 0.218297\n",
      "[581]\tvalid_0's rmse: 0.218285\n",
      "[582]\tvalid_0's rmse: 0.218275\n",
      "[583]\tvalid_0's rmse: 0.218251\n",
      "[584]\tvalid_0's rmse: 0.218242\n",
      "[585]\tvalid_0's rmse: 0.21823\n",
      "[586]\tvalid_0's rmse: 0.218209\n",
      "[587]\tvalid_0's rmse: 0.218195\n",
      "[588]\tvalid_0's rmse: 0.218186\n",
      "[589]\tvalid_0's rmse: 0.218169\n",
      "[590]\tvalid_0's rmse: 0.218158\n",
      "[591]\tvalid_0's rmse: 0.218137\n",
      "[592]\tvalid_0's rmse: 0.218085\n",
      "[593]\tvalid_0's rmse: 0.218057\n",
      "[594]\tvalid_0's rmse: 0.218008\n",
      "[595]\tvalid_0's rmse: 0.217978\n",
      "[596]\tvalid_0's rmse: 0.217944\n",
      "[597]\tvalid_0's rmse: 0.217908\n",
      "[598]\tvalid_0's rmse: 0.217892\n",
      "[599]\tvalid_0's rmse: 0.217876\n",
      "[600]\tvalid_0's rmse: 0.217862\n",
      "[601]\tvalid_0's rmse: 0.217814\n",
      "[602]\tvalid_0's rmse: 0.21778\n",
      "[603]\tvalid_0's rmse: 0.217774\n",
      "[604]\tvalid_0's rmse: 0.217761\n",
      "[605]\tvalid_0's rmse: 0.21772\n",
      "[606]\tvalid_0's rmse: 0.217703\n",
      "[607]\tvalid_0's rmse: 0.217685\n",
      "[608]\tvalid_0's rmse: 0.217668\n",
      "[609]\tvalid_0's rmse: 0.217642\n",
      "[610]\tvalid_0's rmse: 0.217634\n",
      "[611]\tvalid_0's rmse: 0.217625\n",
      "[612]\tvalid_0's rmse: 0.217619\n",
      "[613]\tvalid_0's rmse: 0.217594\n",
      "[614]\tvalid_0's rmse: 0.217574\n",
      "[615]\tvalid_0's rmse: 0.217559\n",
      "[616]\tvalid_0's rmse: 0.217553\n",
      "[617]\tvalid_0's rmse: 0.217539\n",
      "[618]\tvalid_0's rmse: 0.217499\n",
      "[619]\tvalid_0's rmse: 0.217487\n",
      "[620]\tvalid_0's rmse: 0.217449\n",
      "[621]\tvalid_0's rmse: 0.217425\n",
      "[622]\tvalid_0's rmse: 0.217407\n",
      "[623]\tvalid_0's rmse: 0.217361\n",
      "[624]\tvalid_0's rmse: 0.217333\n",
      "[625]\tvalid_0's rmse: 0.217318\n",
      "[626]\tvalid_0's rmse: 0.217263\n",
      "[627]\tvalid_0's rmse: 0.217227\n",
      "[628]\tvalid_0's rmse: 0.217201\n",
      "[629]\tvalid_0's rmse: 0.217185\n",
      "[630]\tvalid_0's rmse: 0.217178\n",
      "[631]\tvalid_0's rmse: 0.217171\n",
      "[632]\tvalid_0's rmse: 0.217148\n",
      "[633]\tvalid_0's rmse: 0.217143\n",
      "[634]\tvalid_0's rmse: 0.217129\n",
      "[635]\tvalid_0's rmse: 0.217125\n",
      "[636]\tvalid_0's rmse: 0.217105\n",
      "[637]\tvalid_0's rmse: 0.217089\n",
      "[638]\tvalid_0's rmse: 0.217083\n",
      "[639]\tvalid_0's rmse: 0.217072\n",
      "[640]\tvalid_0's rmse: 0.217061\n",
      "[641]\tvalid_0's rmse: 0.217058\n",
      "[642]\tvalid_0's rmse: 0.21704\n",
      "[643]\tvalid_0's rmse: 0.216992\n",
      "[644]\tvalid_0's rmse: 0.216977\n",
      "[645]\tvalid_0's rmse: 0.216952\n",
      "[646]\tvalid_0's rmse: 0.216943\n",
      "[647]\tvalid_0's rmse: 0.216932\n",
      "[648]\tvalid_0's rmse: 0.216907\n",
      "[649]\tvalid_0's rmse: 0.216897\n",
      "[650]\tvalid_0's rmse: 0.216893\n",
      "[651]\tvalid_0's rmse: 0.216883\n",
      "[652]\tvalid_0's rmse: 0.216847\n",
      "[653]\tvalid_0's rmse: 0.216837\n",
      "[654]\tvalid_0's rmse: 0.216821\n",
      "[655]\tvalid_0's rmse: 0.216797\n",
      "[656]\tvalid_0's rmse: 0.216795\n",
      "[657]\tvalid_0's rmse: 0.216784\n",
      "[658]\tvalid_0's rmse: 0.21677\n",
      "[659]\tvalid_0's rmse: 0.216765\n",
      "[660]\tvalid_0's rmse: 0.216756\n",
      "[661]\tvalid_0's rmse: 0.216744\n",
      "[662]\tvalid_0's rmse: 0.216728\n",
      "[663]\tvalid_0's rmse: 0.216713\n",
      "[664]\tvalid_0's rmse: 0.216703\n",
      "[665]\tvalid_0's rmse: 0.216669\n",
      "[666]\tvalid_0's rmse: 0.216654\n",
      "[667]\tvalid_0's rmse: 0.216629\n",
      "[668]\tvalid_0's rmse: 0.216622\n",
      "[669]\tvalid_0's rmse: 0.2166\n",
      "[670]\tvalid_0's rmse: 0.216588\n",
      "[671]\tvalid_0's rmse: 0.216557\n",
      "[672]\tvalid_0's rmse: 0.21655\n",
      "[673]\tvalid_0's rmse: 0.21653\n",
      "[674]\tvalid_0's rmse: 0.21651\n",
      "[675]\tvalid_0's rmse: 0.216501\n",
      "[676]\tvalid_0's rmse: 0.216494\n",
      "[677]\tvalid_0's rmse: 0.216491\n",
      "[678]\tvalid_0's rmse: 0.216488\n",
      "[679]\tvalid_0's rmse: 0.216467\n",
      "[680]\tvalid_0's rmse: 0.216454\n",
      "[681]\tvalid_0's rmse: 0.216444\n",
      "[682]\tvalid_0's rmse: 0.216436\n",
      "[683]\tvalid_0's rmse: 0.216417\n",
      "[684]\tvalid_0's rmse: 0.216402\n",
      "[685]\tvalid_0's rmse: 0.216393\n",
      "[686]\tvalid_0's rmse: 0.216363\n",
      "[687]\tvalid_0's rmse: 0.216341\n",
      "[688]\tvalid_0's rmse: 0.216333\n",
      "[689]\tvalid_0's rmse: 0.216323\n",
      "[690]\tvalid_0's rmse: 0.216319\n",
      "[691]\tvalid_0's rmse: 0.216305\n",
      "[692]\tvalid_0's rmse: 0.216296\n",
      "[693]\tvalid_0's rmse: 0.21628\n",
      "[694]\tvalid_0's rmse: 0.216253\n",
      "[695]\tvalid_0's rmse: 0.2162\n",
      "[696]\tvalid_0's rmse: 0.216188\n",
      "[697]\tvalid_0's rmse: 0.216148\n",
      "[698]\tvalid_0's rmse: 0.216126\n",
      "[699]\tvalid_0's rmse: 0.216122\n",
      "[700]\tvalid_0's rmse: 0.216101\n",
      "[701]\tvalid_0's rmse: 0.216083\n",
      "[702]\tvalid_0's rmse: 0.216055\n",
      "[703]\tvalid_0's rmse: 0.216032\n",
      "[704]\tvalid_0's rmse: 0.216012\n",
      "[705]\tvalid_0's rmse: 0.215997\n",
      "[706]\tvalid_0's rmse: 0.215978\n",
      "[707]\tvalid_0's rmse: 0.21594\n",
      "[708]\tvalid_0's rmse: 0.215918\n",
      "[709]\tvalid_0's rmse: 0.2159\n",
      "[710]\tvalid_0's rmse: 0.215887\n",
      "[711]\tvalid_0's rmse: 0.21588\n",
      "[712]\tvalid_0's rmse: 0.21587\n",
      "[713]\tvalid_0's rmse: 0.215861\n",
      "[714]\tvalid_0's rmse: 0.215852\n",
      "[715]\tvalid_0's rmse: 0.215842\n",
      "[716]\tvalid_0's rmse: 0.215837\n",
      "[717]\tvalid_0's rmse: 0.215805\n",
      "[718]\tvalid_0's rmse: 0.215797\n",
      "[719]\tvalid_0's rmse: 0.215789\n",
      "[720]\tvalid_0's rmse: 0.215773\n",
      "[721]\tvalid_0's rmse: 0.215739\n",
      "[722]\tvalid_0's rmse: 0.215722\n",
      "[723]\tvalid_0's rmse: 0.215718\n",
      "[724]\tvalid_0's rmse: 0.215691\n",
      "[725]\tvalid_0's rmse: 0.215682\n",
      "[726]\tvalid_0's rmse: 0.21566\n",
      "[727]\tvalid_0's rmse: 0.215625\n",
      "[728]\tvalid_0's rmse: 0.21561\n",
      "[729]\tvalid_0's rmse: 0.215598\n",
      "[730]\tvalid_0's rmse: 0.215596\n",
      "[731]\tvalid_0's rmse: 0.215577\n",
      "[732]\tvalid_0's rmse: 0.215561\n",
      "[733]\tvalid_0's rmse: 0.215525\n",
      "[734]\tvalid_0's rmse: 0.215518\n",
      "[735]\tvalid_0's rmse: 0.215505\n",
      "[736]\tvalid_0's rmse: 0.215484\n",
      "[737]\tvalid_0's rmse: 0.215471\n",
      "[738]\tvalid_0's rmse: 0.215461\n",
      "[739]\tvalid_0's rmse: 0.215438\n",
      "[740]\tvalid_0's rmse: 0.215424\n",
      "[741]\tvalid_0's rmse: 0.215405\n",
      "[742]\tvalid_0's rmse: 0.215391\n",
      "[743]\tvalid_0's rmse: 0.215385\n",
      "[744]\tvalid_0's rmse: 0.215377\n",
      "[745]\tvalid_0's rmse: 0.215365\n",
      "[746]\tvalid_0's rmse: 0.215353\n",
      "[747]\tvalid_0's rmse: 0.215334\n",
      "[748]\tvalid_0's rmse: 0.215306\n",
      "[749]\tvalid_0's rmse: 0.215292\n",
      "[750]\tvalid_0's rmse: 0.215289\n",
      "[751]\tvalid_0's rmse: 0.215278\n",
      "[752]\tvalid_0's rmse: 0.21526\n",
      "[753]\tvalid_0's rmse: 0.215247\n",
      "[754]\tvalid_0's rmse: 0.21524\n",
      "[755]\tvalid_0's rmse: 0.215232\n",
      "[756]\tvalid_0's rmse: 0.215217\n",
      "[757]\tvalid_0's rmse: 0.215209\n",
      "[758]\tvalid_0's rmse: 0.215188\n",
      "[759]\tvalid_0's rmse: 0.215164\n",
      "[760]\tvalid_0's rmse: 0.215148\n",
      "[761]\tvalid_0's rmse: 0.215127\n",
      "[762]\tvalid_0's rmse: 0.215123\n",
      "[763]\tvalid_0's rmse: 0.21512\n",
      "[764]\tvalid_0's rmse: 0.215111\n",
      "[765]\tvalid_0's rmse: 0.21511\n",
      "[766]\tvalid_0's rmse: 0.2151\n",
      "[767]\tvalid_0's rmse: 0.215094\n",
      "[768]\tvalid_0's rmse: 0.215072\n",
      "[769]\tvalid_0's rmse: 0.215064\n",
      "[770]\tvalid_0's rmse: 0.215052\n",
      "[771]\tvalid_0's rmse: 0.215023\n",
      "[772]\tvalid_0's rmse: 0.215007\n",
      "[773]\tvalid_0's rmse: 0.214988\n",
      "[774]\tvalid_0's rmse: 0.214975\n",
      "[775]\tvalid_0's rmse: 0.21497\n",
      "[776]\tvalid_0's rmse: 0.214949\n",
      "[777]\tvalid_0's rmse: 0.214942\n",
      "[778]\tvalid_0's rmse: 0.214909\n",
      "[779]\tvalid_0's rmse: 0.214908\n",
      "[780]\tvalid_0's rmse: 0.214894\n",
      "[781]\tvalid_0's rmse: 0.214875\n",
      "[782]\tvalid_0's rmse: 0.214868\n",
      "[783]\tvalid_0's rmse: 0.214845\n",
      "[784]\tvalid_0's rmse: 0.214842\n",
      "[785]\tvalid_0's rmse: 0.214821\n",
      "[786]\tvalid_0's rmse: 0.214801\n",
      "[787]\tvalid_0's rmse: 0.214783\n",
      "[788]\tvalid_0's rmse: 0.214776\n",
      "[789]\tvalid_0's rmse: 0.214766\n",
      "[790]\tvalid_0's rmse: 0.214758\n",
      "[791]\tvalid_0's rmse: 0.214749\n",
      "[792]\tvalid_0's rmse: 0.214745\n",
      "[793]\tvalid_0's rmse: 0.214712\n",
      "[794]\tvalid_0's rmse: 0.214706\n",
      "[795]\tvalid_0's rmse: 0.214695\n",
      "[796]\tvalid_0's rmse: 0.214668\n",
      "[797]\tvalid_0's rmse: 0.21465\n",
      "[798]\tvalid_0's rmse: 0.214631\n",
      "[799]\tvalid_0's rmse: 0.214617\n",
      "[800]\tvalid_0's rmse: 0.214608\n",
      "[801]\tvalid_0's rmse: 0.214606\n",
      "[802]\tvalid_0's rmse: 0.214594\n",
      "[803]\tvalid_0's rmse: 0.214589\n",
      "[804]\tvalid_0's rmse: 0.214584\n",
      "[805]\tvalid_0's rmse: 0.214573\n",
      "[806]\tvalid_0's rmse: 0.214565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[807]\tvalid_0's rmse: 0.214564\n",
      "[808]\tvalid_0's rmse: 0.214556\n",
      "[809]\tvalid_0's rmse: 0.214544\n",
      "[810]\tvalid_0's rmse: 0.214522\n",
      "[811]\tvalid_0's rmse: 0.214501\n",
      "[812]\tvalid_0's rmse: 0.214491\n",
      "[813]\tvalid_0's rmse: 0.214478\n",
      "[814]\tvalid_0's rmse: 0.214477\n",
      "[815]\tvalid_0's rmse: 0.214469\n",
      "[816]\tvalid_0's rmse: 0.214466\n",
      "[817]\tvalid_0's rmse: 0.214454\n",
      "[818]\tvalid_0's rmse: 0.214435\n",
      "[819]\tvalid_0's rmse: 0.214427\n",
      "[820]\tvalid_0's rmse: 0.214422\n",
      "[821]\tvalid_0's rmse: 0.214408\n",
      "[822]\tvalid_0's rmse: 0.214405\n",
      "[823]\tvalid_0's rmse: 0.214382\n",
      "[824]\tvalid_0's rmse: 0.214378\n",
      "[825]\tvalid_0's rmse: 0.214363\n",
      "[826]\tvalid_0's rmse: 0.214338\n",
      "[827]\tvalid_0's rmse: 0.214329\n",
      "[828]\tvalid_0's rmse: 0.214313\n",
      "[829]\tvalid_0's rmse: 0.214304\n",
      "[830]\tvalid_0's rmse: 0.214283\n",
      "[831]\tvalid_0's rmse: 0.214253\n",
      "[832]\tvalid_0's rmse: 0.214229\n",
      "[833]\tvalid_0's rmse: 0.214216\n",
      "[834]\tvalid_0's rmse: 0.214202\n",
      "[835]\tvalid_0's rmse: 0.214169\n",
      "[836]\tvalid_0's rmse: 0.214142\n",
      "[837]\tvalid_0's rmse: 0.21411\n",
      "[838]\tvalid_0's rmse: 0.214085\n",
      "[839]\tvalid_0's rmse: 0.214065\n",
      "[840]\tvalid_0's rmse: 0.214046\n",
      "[841]\tvalid_0's rmse: 0.214042\n",
      "[842]\tvalid_0's rmse: 0.214019\n",
      "[843]\tvalid_0's rmse: 0.213988\n",
      "[844]\tvalid_0's rmse: 0.21397\n",
      "[845]\tvalid_0's rmse: 0.213959\n",
      "[846]\tvalid_0's rmse: 0.213948\n",
      "[847]\tvalid_0's rmse: 0.213938\n",
      "[848]\tvalid_0's rmse: 0.213927\n",
      "[849]\tvalid_0's rmse: 0.213921\n",
      "[850]\tvalid_0's rmse: 0.213917\n",
      "[851]\tvalid_0's rmse: 0.2139\n",
      "[852]\tvalid_0's rmse: 0.213891\n",
      "[853]\tvalid_0's rmse: 0.213882\n",
      "[854]\tvalid_0's rmse: 0.213882\n",
      "[855]\tvalid_0's rmse: 0.213878\n",
      "[856]\tvalid_0's rmse: 0.213871\n",
      "[857]\tvalid_0's rmse: 0.213853\n",
      "[858]\tvalid_0's rmse: 0.213838\n",
      "[859]\tvalid_0's rmse: 0.213823\n",
      "[860]\tvalid_0's rmse: 0.213816\n",
      "[861]\tvalid_0's rmse: 0.213786\n",
      "[862]\tvalid_0's rmse: 0.213778\n",
      "[863]\tvalid_0's rmse: 0.21377\n",
      "[864]\tvalid_0's rmse: 0.213763\n",
      "[865]\tvalid_0's rmse: 0.213756\n",
      "[866]\tvalid_0's rmse: 0.213729\n",
      "[867]\tvalid_0's rmse: 0.213718\n",
      "[868]\tvalid_0's rmse: 0.213702\n",
      "[869]\tvalid_0's rmse: 0.213689\n",
      "[870]\tvalid_0's rmse: 0.213671\n",
      "[871]\tvalid_0's rmse: 0.213652\n",
      "[872]\tvalid_0's rmse: 0.213637\n",
      "[873]\tvalid_0's rmse: 0.213635\n",
      "[874]\tvalid_0's rmse: 0.213625\n",
      "[875]\tvalid_0's rmse: 0.213611\n",
      "[876]\tvalid_0's rmse: 0.213595\n",
      "[877]\tvalid_0's rmse: 0.213566\n",
      "[878]\tvalid_0's rmse: 0.21355\n",
      "[879]\tvalid_0's rmse: 0.213541\n",
      "[880]\tvalid_0's rmse: 0.213523\n",
      "[881]\tvalid_0's rmse: 0.213511\n",
      "[882]\tvalid_0's rmse: 0.213497\n",
      "[883]\tvalid_0's rmse: 0.21348\n",
      "[884]\tvalid_0's rmse: 0.213461\n",
      "[885]\tvalid_0's rmse: 0.213453\n",
      "[886]\tvalid_0's rmse: 0.21343\n",
      "[887]\tvalid_0's rmse: 0.213421\n",
      "[888]\tvalid_0's rmse: 0.213416\n",
      "[889]\tvalid_0's rmse: 0.213401\n",
      "[890]\tvalid_0's rmse: 0.213366\n",
      "[891]\tvalid_0's rmse: 0.213364\n",
      "[892]\tvalid_0's rmse: 0.213343\n",
      "[893]\tvalid_0's rmse: 0.213332\n",
      "[894]\tvalid_0's rmse: 0.213312\n",
      "[895]\tvalid_0's rmse: 0.213303\n",
      "[896]\tvalid_0's rmse: 0.213285\n",
      "[897]\tvalid_0's rmse: 0.213282\n",
      "[898]\tvalid_0's rmse: 0.213276\n",
      "[899]\tvalid_0's rmse: 0.213257\n",
      "[900]\tvalid_0's rmse: 0.213239\n",
      "[901]\tvalid_0's rmse: 0.213227\n",
      "[902]\tvalid_0's rmse: 0.213217\n",
      "[903]\tvalid_0's rmse: 0.21319\n",
      "[904]\tvalid_0's rmse: 0.213185\n",
      "[905]\tvalid_0's rmse: 0.213146\n",
      "[906]\tvalid_0's rmse: 0.21314\n",
      "[907]\tvalid_0's rmse: 0.21312\n",
      "[908]\tvalid_0's rmse: 0.213118\n",
      "[909]\tvalid_0's rmse: 0.213096\n",
      "[910]\tvalid_0's rmse: 0.213095\n",
      "[911]\tvalid_0's rmse: 0.213093\n",
      "[912]\tvalid_0's rmse: 0.21309\n",
      "[913]\tvalid_0's rmse: 0.213084\n",
      "[914]\tvalid_0's rmse: 0.213081\n",
      "[915]\tvalid_0's rmse: 0.213061\n",
      "[916]\tvalid_0's rmse: 0.213059\n",
      "[917]\tvalid_0's rmse: 0.213044\n",
      "[918]\tvalid_0's rmse: 0.213019\n",
      "[919]\tvalid_0's rmse: 0.213015\n",
      "[920]\tvalid_0's rmse: 0.213014\n",
      "[921]\tvalid_0's rmse: 0.213005\n",
      "[922]\tvalid_0's rmse: 0.212999\n",
      "[923]\tvalid_0's rmse: 0.212991\n",
      "[924]\tvalid_0's rmse: 0.212967\n",
      "[925]\tvalid_0's rmse: 0.212931\n",
      "[926]\tvalid_0's rmse: 0.212905\n",
      "[927]\tvalid_0's rmse: 0.212902\n",
      "[928]\tvalid_0's rmse: 0.212896\n",
      "[929]\tvalid_0's rmse: 0.212889\n",
      "[930]\tvalid_0's rmse: 0.212881\n",
      "[931]\tvalid_0's rmse: 0.212856\n",
      "[932]\tvalid_0's rmse: 0.212847\n",
      "[933]\tvalid_0's rmse: 0.212831\n",
      "[934]\tvalid_0's rmse: 0.212807\n",
      "[935]\tvalid_0's rmse: 0.2128\n",
      "[936]\tvalid_0's rmse: 0.212789\n",
      "[937]\tvalid_0's rmse: 0.212788\n",
      "[938]\tvalid_0's rmse: 0.212783\n",
      "[939]\tvalid_0's rmse: 0.212767\n",
      "[940]\tvalid_0's rmse: 0.212758\n",
      "[941]\tvalid_0's rmse: 0.212723\n",
      "[942]\tvalid_0's rmse: 0.2127\n",
      "[943]\tvalid_0's rmse: 0.212682\n",
      "[944]\tvalid_0's rmse: 0.21267\n",
      "[945]\tvalid_0's rmse: 0.21264\n",
      "[946]\tvalid_0's rmse: 0.212613\n",
      "[947]\tvalid_0's rmse: 0.212596\n",
      "[948]\tvalid_0's rmse: 0.212558\n",
      "[949]\tvalid_0's rmse: 0.212552\n",
      "[950]\tvalid_0's rmse: 0.212549\n",
      "[951]\tvalid_0's rmse: 0.212517\n",
      "[952]\tvalid_0's rmse: 0.212512\n",
      "[953]\tvalid_0's rmse: 0.212507\n",
      "[954]\tvalid_0's rmse: 0.212503\n",
      "[955]\tvalid_0's rmse: 0.212484\n",
      "[956]\tvalid_0's rmse: 0.21248\n",
      "[957]\tvalid_0's rmse: 0.212475\n",
      "[958]\tvalid_0's rmse: 0.212443\n",
      "[959]\tvalid_0's rmse: 0.212428\n",
      "[960]\tvalid_0's rmse: 0.212427\n",
      "[961]\tvalid_0's rmse: 0.212388\n",
      "[962]\tvalid_0's rmse: 0.212382\n",
      "[963]\tvalid_0's rmse: 0.212374\n",
      "[964]\tvalid_0's rmse: 0.212367\n",
      "[965]\tvalid_0's rmse: 0.212366\n",
      "[966]\tvalid_0's rmse: 0.212366\n",
      "[967]\tvalid_0's rmse: 0.212348\n",
      "[968]\tvalid_0's rmse: 0.212336\n",
      "[969]\tvalid_0's rmse: 0.21232\n",
      "[970]\tvalid_0's rmse: 0.212312\n",
      "[971]\tvalid_0's rmse: 0.212306\n",
      "[972]\tvalid_0's rmse: 0.212299\n",
      "[973]\tvalid_0's rmse: 0.212294\n",
      "[974]\tvalid_0's rmse: 0.212273\n",
      "[975]\tvalid_0's rmse: 0.21227\n",
      "[976]\tvalid_0's rmse: 0.212266\n",
      "[977]\tvalid_0's rmse: 0.212249\n",
      "[978]\tvalid_0's rmse: 0.212242\n",
      "[979]\tvalid_0's rmse: 0.212234\n",
      "[980]\tvalid_0's rmse: 0.212226\n",
      "[981]\tvalid_0's rmse: 0.2122\n",
      "[982]\tvalid_0's rmse: 0.212171\n",
      "[983]\tvalid_0's rmse: 0.212167\n",
      "[984]\tvalid_0's rmse: 0.212155\n",
      "[985]\tvalid_0's rmse: 0.212134\n",
      "[986]\tvalid_0's rmse: 0.212122\n",
      "[987]\tvalid_0's rmse: 0.212105\n",
      "[988]\tvalid_0's rmse: 0.21208\n",
      "[989]\tvalid_0's rmse: 0.212061\n",
      "[990]\tvalid_0's rmse: 0.212056\n",
      "[991]\tvalid_0's rmse: 0.21205\n",
      "[992]\tvalid_0's rmse: 0.212038\n",
      "[993]\tvalid_0's rmse: 0.212032\n",
      "[994]\tvalid_0's rmse: 0.212019\n",
      "[995]\tvalid_0's rmse: 0.212017\n",
      "[996]\tvalid_0's rmse: 0.212015\n",
      "[997]\tvalid_0's rmse: 0.212012\n",
      "[998]\tvalid_0's rmse: 0.212001\n",
      "[999]\tvalid_0's rmse: 0.211982\n",
      "[1000]\tvalid_0's rmse: 0.211977\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.211977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "       n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMRegressor(n_estimators=1000)\n",
    "model.fit(X_train,y_train,\n",
    "    eval_set = [(X_valid,y_valid)],\n",
    "    early_stopping_rounds=10,\n",
    "    eval_metric=\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose large number of trees/rounds (1000) and \"aggressive\" early stopping (10) to avoid overfitting. However, it actually reached the 1000 iterations. This number is not \"insanely\" high but is higher that what I am normally used to using lightGBM. \n",
    "\n",
    "My intention here is to \"quickly\" go through the process. However, if you think this might be your favourite final solution for your recommendation algorithm, you would need to explore more. For example, we have used 100 components, but maybe (probably) 150 or 200 capture better the local (or \"regional\") effects. If you choose to use lightGBM, you would want to perform a proper optimization process, tunning some of the relevant parameters, as illustrated in the previous chapter. Maybe more regularization or a higher number of leaves leads to a lower number of boosting rounds.\n",
    "\n",
    "Also, remember these are all numerical features, in total 200. This normally makes things slightly simpler. In this scenario you might want to try libraries like [tpot](https://epistasislab.github.io/tpot/) for automatic ML with genetic programming (if you have the time and the memory) or [ml-lens](http://ml-ensemble.com/info/start/ensembles.html) to build ensemble algorithms. \n",
    "\n",
    "Nonetheless, for the time being, let's move forward and load the dictionary of interactions during validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the interactions during validation\n",
    "interactions_valid_dict = pickle.load(\n",
    "    open(\"../datasets/Ponpare/data_processed/valid/interactions_valid_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jrz/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2173418, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>282b5bda1758e147589ca517e02195c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>0f43ef71c25d409c250f5a5042806342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>28ff0fb4b561a2fd6a360fe28f465e07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>864f351e66cd3aeece5d06987fc2ed4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>279ba64539609d30114b68874cd0fb42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash                    coupon_id_hash\n",
       "0  002ae30377cd30f65652e52618e8b2d6  282b5bda1758e147589ca517e02195c3\n",
       "1  002ae30377cd30f65652e52618e8b2d6  0f43ef71c25d409c250f5a5042806342\n",
       "2  002ae30377cd30f65652e52618e8b2d6  28ff0fb4b561a2fd6a360fe28f465e07\n",
       "3  002ae30377cd30f65652e52618e8b2d6  864f351e66cd3aeece5d06987fc2ed4b\n",
       "4  002ae30377cd30f65652e52618e8b2d6  279ba64539609d30114b68874cd0fb42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = pd.DataFrame({'user_id_hash':list(interactions_valid_dict.keys())})\n",
    "left['key'] = 0\n",
    "right = df_coupons_valid_feat[['coupon_id_hash']]\n",
    "right['key'] = 0\n",
    "df_valid = (pd.merge(left, right, on='key', how='outer')\n",
    "    .drop('key', axis=1))\n",
    "print(df_valid.shape)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the user latent factors and map validation into training coupons to use coupon latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2173060, 203)\n"
     ]
    }
   ],
   "source": [
    "# Coupon factors\n",
    "df_valid['mapped_coupons'] = (df_valid.coupon_id_hash\n",
    "    .apply(lambda x: valid_to_train_most_similar[x]))\n",
    "df_valid = pd.merge(df_valid, df_item_factors,\n",
    "    left_on='mapped_coupons', right_on='coupon_id_hash')\n",
    "df_valid.drop('coupon_id_hash_y', axis=1, inplace=True)\n",
    "df_valid.rename(index=str, columns={'coupon_id_hash_x': 'coupon_id_hash'}, inplace=True)\n",
    "\n",
    "# User\n",
    "df_valid = pd.merge(df_valid, df_user_factors, on='user_id_hash')\n",
    "print(df_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = df_valid.iloc[:, 3:].values\n",
    "preds = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the interest column and rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = df_valid[['user_id_hash', 'coupon_id_hash']]\n",
    "df_preds['interest'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021966114031188165\n"
     ]
    }
   ],
   "source": [
    "df_ranked = df_preds.sort_values(['user_id_hash', 'interest'], ascending=[False, False])\n",
    "df_ranked = (df_ranked\n",
    "    .groupby('user_id_hash')['coupon_id_hash']\n",
    "    .apply(list)\n",
    "    .reset_index())\n",
    "recomendations_dict = pd.Series(df_ranked.coupon_id_hash.values,\n",
    "    index=df_ranked.user_id_hash).to_dict()\n",
    "\n",
    "actual = []\n",
    "pred = []\n",
    "for k,_ in recomendations_dict.items():\n",
    "    actual.append(list(interactions_valid_dict[k]))\n",
    "    pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "print(mapk(actual,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sim 0.22$ not as good as some previous techniques. However, remember, the first MAP value we obtained when in Chapter 10 during our optimization process was 0.020. Eventually, we managed to push it up to 0.032. Therefore, as I mentioned before, if you think this is your favourite technique, you should carry out a proper optimization process. That process should also include the number of components/factors as a hyperparameter to be tuned. \n",
    "\n",
    "Note that the latent factors can be useful for a number of things other than recommending. They have been learned based on users' behaviour. Therefore, you might want to use them for campaign targetting instead of demographic-based features (such as age, location, etc) for example. In this scenario, you will be targetting your users based on their behaviour instead of some \"human-readable\" features, which is possibly more adequate. \n",
    "\n",
    "Before we leave this notebook make sure you are familiar with the concept of latent factors, since similar principles with a different formulation will be applied when using our next technique: Factorization Machines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jrz)",
   "language": "python",
   "name": "conda_jrz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
