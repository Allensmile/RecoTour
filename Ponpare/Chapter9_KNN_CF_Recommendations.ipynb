{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 9\n",
    "\n",
    "### 1. KNN Collaborative Filtering\n",
    "\n",
    "The amount of blog posts and literature one can find regarding to this technique is *gigantic*. Therefore, I will not spend much time explaining how it works. For example, have a look [here](https://beckernick.github.io/music_recommender/). Let me also use this opportunity to recommend one of the few good books about recommender systems: [Recommender Systems](https://www.amazon.co.uk/Recommender-Systems-Textbook-Charu-Aggarwal/dp/3319296574/ref=sr_1_1?ie=UTF8&qid=1531491611&sr=8-1&keywords=recommender+systems). \n",
    "\n",
    "Nonetheless, here is a quick explanation. In Chapter 8 we built an \"Interaction Matrix\" (hereafter $R$) of dimensions $U\\times I$ where $U$ is the number of users and $I$ is the number of items. Each element of that matrix $R_{ij}$ is the interest of user $i$ in coupon $j$. If we transpose this matrix ($R^{T}$) we can use it to compute the similarity between coupons based on user interest. Then, if a user has shown interest in a given coupon, we can recommend similar coupons based on that similarity metric. In other words, we can recommend similar items using item-based collaborative filtering. \n",
    "\n",
    "However, as straightforward this approach might sound, there is an issue to we need to address here for this particular problem, and in any approach that is based purely on past interaction between users and items. This is, the coupons that need to be recommended in a given week, have never been seen before. Therefore, they are not in $R$. \n",
    "\n",
    "In real life, one could do the following, if one decides to go with this approach: \n",
    "\n",
    "1. As in previous chapters, we could compute the distance between validation and training coupons using only coupon features. \n",
    "2. We could then build a dictionary mapping validation into training coupons.\n",
    "3. Use kNN CF \"as usual\". \n",
    "4. Once we have the recommended training coupons, we can map them back to validation. \n",
    "\n",
    "As you might have guessed, this approach will be very slow, but will it perform well enough so we can trade some speed? let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.sparse import csr_matrix, load_npz\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from recutils.average_precision import mapk\n",
    "\n",
    "inp_dir = \"../datasets/Ponpare/data_processed/\"\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupons_train_feat = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_coupons_train_feat.p'))\n",
    "df_coupons_valid_feat = pd.read_pickle(os.path.join(inp_dir, valid_dir, 'df_coupons_valid_feat.p'))\n",
    "coupons_train_ids = df_coupons_train_feat.coupon_id_hash.values\n",
    "coupons_valid_ids = df_coupons_valid_feat.coupon_id_hash.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a different approach to compute the distance between train and validation coupons that the one described in Chapter 6. There we combined euclidean and jaccard distances for the numerical and one-hot encoded features separately. Here we will stack the two feature-sets and use the cosine distance.\n",
    "\n",
    "Let's first get the one-hot encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coupons_train_feat['flag'] = 0\n",
    "df_coupons_valid_feat['flag'] = 1\n",
    "\n",
    "cat_cols = [c for c in df_coupons_train_feat.columns if '_cat' in c]\n",
    "id_cols = ['coupon_id_hash']\n",
    "num_cols = [c for c in df_coupons_train_feat.columns if\n",
    "    (c not in cat_cols) and (c not in id_cols)]\n",
    "\n",
    "tmp_df = pd.concat([\n",
    "    df_coupons_train_feat[cat_cols+['flag']],\n",
    "    df_coupons_valid_feat[cat_cols+['flag']]\n",
    "    ],\n",
    "    ignore_index=True)\n",
    "\n",
    "df_dummy_feats = pd.get_dummies(tmp_df, columns=cat_cols)\n",
    "\n",
    "coupons_train_feat_oh = (df_dummy_feats[df_dummy_feats.flag == 0]\n",
    "    .drop('flag', axis=1)\n",
    "    .values)\n",
    "coupons_valid_feat_oh = (df_dummy_feats[df_dummy_feats.flag == 1]\n",
    "    .drop('flag', axis=1)\n",
    "    .values)\n",
    "del(tmp_df, df_dummy_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the numeric ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jrz/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "coupons_train_feat_num = df_coupons_train_feat[num_cols].values\n",
    "coupons_valid_feat_num = df_coupons_valid_feat[num_cols].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "coupons_train_feat_num_norm = scaler.fit_transform(coupons_train_feat_num)\n",
    "coupons_valid_feat_num_norm = scaler.transform(coupons_valid_feat_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack -> distance -> to dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupons_train_feat = np.hstack([coupons_train_feat_num_norm, coupons_train_feat_oh])\n",
    "coupons_valid_feat = np.hstack([coupons_valid_feat_num_norm, coupons_valid_feat_oh])\n",
    "\n",
    "dist_mtx = pairwise_distances(coupons_valid_feat, coupons_train_feat, metric='cosine')\n",
    "\n",
    "valid_to_train_top_n_idx = np.apply_along_axis(np.argsort, 1, dist_mtx)\n",
    "train_to_valid_top_n_idx = np.apply_along_axis(np.argsort, 1, dist_mtx.T)\n",
    "\n",
    "# there is one coupon in validation: '0a8e967835e2c20ac4ed8e69ee3d7349' that\n",
    "# is never among the most similar to those previously seen.\n",
    "train_to_valid_most_similar = dict(zip(coupons_train_ids,\n",
    "    coupons_valid_ids[train_to_valid_top_n_idx[:,0]]))\n",
    "valid_to_train_most_similar = dict(zip(coupons_valid_ids,\n",
    "    coupons_train_ids[valid_to_train_top_n_idx[:,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jrz)",
   "language": "python",
   "name": "conda_jrz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
