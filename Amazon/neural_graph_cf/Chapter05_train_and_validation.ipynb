{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Let's start by manually defining some neccesary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import scipy.sparse as sp\n",
    "import multiprocessing\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from time import time\n",
    "from functools import partial\n",
    "from utils.dataset import Data\n",
    "from utils.metrics import ranklist_by_heapq, get_performance\n",
    "# from utils.parser import parse_args\n",
    "from ngcf import NGCF_BPR\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will notice that I import `NGCF_BPR` not simply `NGCF`. This is because there is another class in the `ngcf` module called `NGCF_BCE` which is coded to simply predict 1/0 interaction or not \"*a la traditional classification*\" problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users=1000, n_items=2000\n",
      "n_interactions=30780\n",
      "n_train=24228, n_test=6552, sparsity=0.01539\n",
      "already load adj matrix (3000, 3000) 0.013494253158569336\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "Ks = [10, 20]\n",
    "\n",
    "data_path = \"Data/toy_data/\"\n",
    "batch_size = 64\n",
    "data_generator = Data(data_path, batch_size, val=False)\n",
    "n_users = data_generator.n_users\n",
    "n_items = data_generator.n_items\n",
    "\n",
    "_, _, mean_adj = data_generator.get_adj_mat()\n",
    "adjacency_matrix = mean_adj + sp.eye(mean_adj.shape[0])\n",
    "\n",
    "emb_size = 12\n",
    "layers = [12, 6]\n",
    "node_dropout = 0.1\n",
    "mess_dropout = [0.1]*len(layers)\n",
    "regularization = 1e-5\n",
    "lr = 0.01\n",
    "n_fold = 10\n",
    "\n",
    "pretrain = 0\n",
    "\n",
    "print_every, eval_every, save_every = 1, 1, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NGCF_BPR(n_users, n_items, emb_size, adjacency_matrix, layers,\n",
    "    node_dropout, mess_dropout, regularization, n_fold, batch_size)\n",
    "if use_cuda: \n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_user\n",
      "embeddings_item\n",
      "W1.0.weight\n",
      "W1.0.bias\n",
      "W1.1.weight\n",
      "W1.1.bias\n",
      "W2.0.weight\n",
      "W2.0.bias\n",
      "W2.1.weight\n",
      "W2.1.bias\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    if p.requires_grad: print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is it really regarding the parameters of the model. We only need the user/item embeddings and then a series of linear layers (that we could refer as graph layers). The embeddings will be concatenated over rows, multiplied by the Laplacian matrix, and then passed through a the graph/linear layers recursively. \n",
    "\n",
    "Let's now move to the training phase. The training phase is your typical pytorch training function, with the exception that the output of the forward pass is already the [BPR](https://arxiv.org/pdf/1205.2618.pdf) loss. It goes this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_generator, optimizer):\n",
    "    model.train()\n",
    "    n_batch = data_generator.n_train // data_generator.batch_size + 1\n",
    "    running_loss=0\n",
    "    for _ in range(n_batch):\n",
    "        # tuple (users, positive items, negative items)     \n",
    "        u, i, j = data_generator.sample()\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(u,i,j)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not talked about the BPR loss yet, so let's have a look. The definition in the [paper](https://arxiv.org/pdf/1905.08108.pdf) is:\n",
    "\n",
    "$$\n",
    "Loss = \\sum_{(u,i,j) \\in \\mathcal{O}} -ln \\big(\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})\\big) + \\lambda ||\\Theta||^{2}_{2}\n",
    "$$\n",
    "\n",
    "Where $\\mathcal{O} = \\{ (u,i,j)|(u,i) \\in  R^{+}, (u,j) \\in R^{-} \\}$ is the set of training tuples with $R^{+}$ and $R^{-}$ corresponding to observed and unobserved interactions (aka positive and negative) respectively. $\\sigma$ is the sigmoid function and $||\\Theta|| = \\{ \\text{E}, \\{ \\textbf{W}^{l}_{1},\\textbf{W}^{l}_{2} \\}^{L}_{l=1}  \\}$ are all training parameters. \n",
    "\n",
    "In pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(self, u, i, j):\n",
    "    # first term\n",
    "    y_ui = torch.mul(u, i).sum(dim=1)\n",
    "    y_uj = torch.mul(u, j).sum(dim=1)\n",
    "    log_prob = (torch.log(torch.sigmoid(y_ui-y_uj))).mean()\n",
    "\n",
    "    # regularization\n",
    "    l2norm = (torch.sum(u**2)/2. + torch.sum(i**2)/2. + torch.sum(j**2)/2.).mean()\n",
    "    l2reg  = reg*l2norm\n",
    "\n",
    "    #Â Loss\n",
    "    return -log_prob + l2reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, so now we now how the training happens, let's move to the validation/testing. Here, we will first use the authors `early_stopping` function. I am sure there are more \"pytorchian\" ways of doing it, but this function is simple and does the job, so let's use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(log_value, best_value, stopping_step, expected_order='asc', patience=10):\n",
    "\n",
    "    # better is higher or lower\n",
    "    assert expected_order in ['asc', 'dec']\n",
    "\n",
    "    if (expected_order == 'asc' and log_value >= best_value) or (expected_order == 'dec' and log_value <= best_value):\n",
    "        stopping_step = 0\n",
    "        best_value = log_value\n",
    "    else:\n",
    "        stopping_step += 1\n",
    "\n",
    "    if stopping_step >= patience:\n",
    "        print(\"Early stopping is trigger at step: {} log:{}\".format(patience, log_value))\n",
    "        should_stop = True\n",
    "    else:\n",
    "        should_stop = False\n",
    "\n",
    "    return best_value, stopping_step, should_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we test on one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_user(x):\n",
    "    \"\"\"\n",
    "    x will be a zip object where the 1st element will be the user id and the 2nd\n",
    "    will be the scores for all items in the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    u = x[0]\n",
    "    rating = x[1]\n",
    "\n",
    "    try:\n",
    "        training_items = data_generator.train_items[u]\n",
    "    except Exception:\n",
    "        training_items = []\n",
    "\n",
    "    # items that the user did interact with during testing\n",
    "    user_pos_test = data_generator.test_set[u]\n",
    "    all_items = set(range(data_generator.n_items))\n",
    "    # test_items include negative items and  user_pos_test\n",
    "    test_items = list(all_items - set(training_items))\n",
    "\n",
    "    # and now we compute the metrics as described in the notebook Chapter03_metrics.ipynb.\n",
    "    r, auc = ranklist_by_heapq(user_pos_test, test_items, rating, Ks)\n",
    "\n",
    "    return get_performance(user_pos_test, r, auc, Ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we know how to test in one user, let's do it for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_generator):\n",
    "\n",
    "    result = {\n",
    "        'precision': np.zeros(len(Ks)),\n",
    "        'recall': np.zeros(len(Ks)),\n",
    "        'ndcg': np.zeros(len(Ks)),\n",
    "        'hit_ratio': np.zeros(len(Ks)),\n",
    "        'auc': 0.\n",
    "        }\n",
    "\n",
    "    # here we can use larger batches\n",
    "    u_batch_size = data_generator.batch_size * 2\n",
    "\n",
    "    # test users are all users really\n",
    "    test_users = list(data_generator.test_set.keys())\n",
    "    n_test_users = len(test_users)\n",
    "    n_user_batchs = n_test_users // u_batch_size + 1\n",
    "    \n",
    "    # n_test_items are normally all items\n",
    "    n_test_items = data_generator.n_items\n",
    "\n",
    "    count = 0\n",
    "    p = Pool(cores)\n",
    "    for u_batch_id in range(n_user_batchs):\n",
    "        start = u_batch_id * u_batch_size\n",
    "        end = (u_batch_id + 1) * u_batch_size\n",
    "\n",
    "        user_batch = test_users[start: end]\n",
    "        item_batch = np.arange(n_test_items)\n",
    "    \n",
    "        # ratings are simply the matrix multiplication of the graph embeddings. One option \n",
    "        # could be wrap this up into a sigmoid, to keep all between 0,1\n",
    "        rate_batch  = torch.mm(model.g_embeddings_user, model.g_embeddings_item.t())\n",
    "\n",
    "        # detach and to CPU so it can be parallelised through the cores\n",
    "        rate_batch_np = rate_batch.detach().cpu().numpy()\n",
    "        batch_result = p.map(test_one_user, zip(user_batch,rate_batch_np))\n",
    "\n",
    "        count += len(batch_result)\n",
    "\n",
    "        for re in batch_result:\n",
    "            result['precision'] += re['precision']/n_test_users\n",
    "            result['recall'] += re['recall']/n_test_users\n",
    "            result['ndcg'] += re['ndcg']/n_test_users\n",
    "            result['hit_ratio'] += re['hit_ratio']/n_test_users\n",
    "            result['auc'] += re['auc']/n_test_users\n",
    "    assert count == n_test_users\n",
    "    p.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how all comes together! (Note that the process here is **extremely** inefficient since we are splitting a 3000x3000 matrix into 10 folds and using a 32 batch for only 1000 users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 95.76s, Loss = 245.9971\n",
      "VALIDATION. \n",
      "Epoch: 0, 0.66s \n",
      " Recall@10: 0.0056, Recall@20: 0.0098 \n",
      "Precision@10: 0.0032, Precision@20: 0.0029 \n",
      "Hit_ratio@10: 0.0320, Hit_ratio@20: 0.0570 \n",
      "NDCG@10: 0.0162, NDCG@20: 0.0224\n",
      "Epoch:1 95.33s, Loss = 228.0495\n",
      "VALIDATION. \n",
      "Epoch: 1, 0.67s \n",
      " Recall@10: 0.0050, Recall@20: 0.0076 \n",
      "Precision@10: 0.0032, Precision@20: 0.0026 \n",
      "Hit_ratio@10: 0.0320, Hit_ratio@20: 0.0510 \n",
      "NDCG@10: 0.0127, NDCG@20: 0.0175\n"
     ]
    }
   ],
   "source": [
    "cur_best_pre = 0.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "stopping_step, should_stop = 0, False\n",
    "for epoch in range(2):\n",
    "    t1 = time()\n",
    "    loss = train(model, data_generator, optimizer)\n",
    "    if epoch % print_every  == (print_every - 1):\n",
    "        print(\"Epoch:{} {:.2f}s, Loss = {:.4f}\".\n",
    "            format(epoch, time()-t1, loss))\n",
    "    if epoch % eval_every  == (eval_every - 1):\n",
    "        t2 = time()\n",
    "        res = test(model, data_generator)\n",
    "        print(\"VALIDATION.\",\"\\n\"\n",
    "            \"Epoch: {}, {:.2f}s\".format(epoch, time()-t2),\"\\n\",\n",
    "            \"Recall@{}: {:.4f}, Recall@{}: {:.4f}\".format(Ks[0], res['recall'][0],  Ks[-1], res['recall'][-1]), \"\\n\"\n",
    "            \"Precision@{}: {:.4f}, Precision@{}: {:.4f}\".format(Ks[0], res['precision'][0],  Ks[-1], res['precision'][-1]), \"\\n\"\n",
    "            \"Hit_ratio@{}: {:.4f}, Hit_ratio@{}: {:.4f}\".format(Ks[0], res['hit_ratio'][0],  Ks[-1], res['hit_ratio'][-1]), \"\\n\"\n",
    "            \"NDCG@{}: {:.4f}, NDCG@{}: {:.4f}\".format(Ks[0], res['ndcg'][0],  Ks[-1], res['ndcg'][-1])\n",
    "            )\n",
    "        cur_best_pre, stopping_step, should_stop = \\\n",
    "        early_stopping(res['recall'][0], cur_best_pre, stopping_step)\n",
    "    if epoch % save_every == (save_every - 1):\n",
    "        torch.save(model.state_dict(), modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember, in the notebook `Chapter03_metrics.ipynb` I described another form of testing inspired by the code in [this repo](https://github.com/sh0416/bpr/blob/master/train.py). Let's revisit the code. A full explanation of the code flow is in that notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def split_mtx(X, n_folds=10):\n",
    "    \"\"\"\n",
    "    Split a matrix/tensor in n_folds folds\n",
    "    \n",
    "    There is some redundancy with the split methods within the \n",
    "    NGCF_BPR class...I am ok with that, or almost.\n",
    "    \"\"\"\n",
    "    X_folds = []\n",
    "    fold_len = X.shape[0]//n_folds\n",
    "    for i in range(n_folds):\n",
    "        start = i * fold_len\n",
    "        if i == n_folds -1:\n",
    "            end = X.shape[0]\n",
    "        else:\n",
    "            end = (i + 1) * fold_len\n",
    "        X_folds.append(X[start:end])\n",
    "    return X_folds\n",
    "\n",
    "# this was named \"precision_and_recall_k\"\n",
    "def test_GPU(user_emb, item_emb, R_tr, R_te, Ks):\n",
    "\n",
    "    tr_folds = split_mtx(R_tr)\n",
    "    te_folds = split_mtx(R_te)\n",
    "    ue_folds = split_mtx(user_emb)\n",
    "\n",
    "    fold_prec, fold_rec = {}, {}\n",
    "    for ue_fold, tr_fold, te_fold in zip(ue_folds, tr_folds, te_folds):\n",
    "\n",
    "        result = torch.sigmoid(torch.mm(ue_fold, item_emb.t()))\n",
    "        test_pred_mask = torch.from_numpy(1 - tr_fold.todense())\n",
    "        test_true_mask = torch.from_numpy(te_fold.todense())\n",
    "        if use_cuda:\n",
    "            test_pred_mask, test_true_mask = test_pred_mask.cuda(), test_true_mask.cuda()\n",
    "        test_pred = test_pred_mask * result\n",
    "        test_true = test_true_mask * result\n",
    "\n",
    "        _, test_indices = torch.topk(test_pred, dim=1, k=max(Ks))\n",
    "        for k in Ks:\n",
    "            topk_mask = torch.zeros_like(test_pred)\n",
    "            source = torch.tensor(1.0).cuda() if use_cuda else torch.tensor(1.0)\n",
    "            topk_mask.scatter_(dim=1, index=test_indices[:, :k], src=source)\n",
    "            test_pred_topk = topk_mask * test_pred\n",
    "            acc_result = (test_pred_topk != 0) & (test_pred_topk == test_true)\n",
    "            pr_k = acc_result.sum().float() / (user_emb.shape[0] * k)\n",
    "            rec_k = (acc_result.float().sum(dim=1) / test_true_mask.float().sum(dim=1))\n",
    "            try:\n",
    "                fold_prec[k].append(pr_k)\n",
    "                fold_rec[k].append(rec_k)\n",
    "            except KeyError:\n",
    "                fold_prec[k] = [pr_k]\n",
    "                fold_rec[k] = [rec_k]\n",
    "\n",
    "    precision, recall = {}, {}\n",
    "    for k in Ks:\n",
    "        precision[k] = np.sum(fold_prec[k])\n",
    "        recall[k] = torch.cat(fold_rec[k]).mean()\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use it, one would simply replace `test` with `test_GPU` and: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre, rec = test_GPU(\n",
    "    model.g_embeddings_user, \n",
    "    model.g_embeddings_item, \n",
    "    data_generator.Rtr, \n",
    "    data_generator.Rte, \n",
    "    Ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: tensor(0.0037, device='cuda:0'), 20: tensor(0.0040, device='cuda:0')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
