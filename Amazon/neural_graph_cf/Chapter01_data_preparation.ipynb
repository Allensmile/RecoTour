{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Movies Data Preparation\n",
    "\n",
    "To start with simply download the dataset:\n",
    "\n",
    "`wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Movies_and_TV_5.json.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/Users/javier/ml_exercises_python/RecoTour/Amazon/neural_graph_cf/Data/amazon-movies/\")\n",
    "reviews = \"reviews_Movies_and_TV_5.json.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADZPIG9QOCDG5</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>1203984000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A35947ZP82G7JH</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3UORV8A9D5L2E</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VKW06X1O2X7V</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>1202860800</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R27T4HADWFFJ</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>1387670400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item   timestamp  rating\n",
       "0   ADZPIG9QOCDG5  0005019281  1203984000       4\n",
       "1  A35947ZP82G7JH  0005019281  1388361600       3\n",
       "2  A3UORV8A9D5L2E  0005019281  1388361600       3\n",
       "3  A1VKW06X1O2X7V  0005019281  1202860800       5\n",
       "4  A3R27T4HADWFFJ  0005019281  1387670400       4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(DATA_PATH/reviews, lines=True)\n",
    "keep_cols = ['reviewerID', 'asin', 'unixReviewTime', 'overall']\n",
    "new_colnames = ['user', 'item', 'timestamp', 'rating']\n",
    "df = df[keep_cols]\n",
    "df.columns = new_colnames\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    906608\n",
       "4    382994\n",
       "3    201302\n",
       "1    104219\n",
       "2    102410\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a lot of people seem to love the movies they watch. There are more 5s that 1,2,3 and 4s together. \n",
    "\n",
    "For convenience later, let's now sort values based on `timestamp`. This will be useful later in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00295401U6S2UG3RAQSZ</td>\n",
       "      <td>0767015533</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00295401U6S2UG3RAQSZ</td>\n",
       "      <td>0792838084</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00295401U6S2UG3RAQSZ</td>\n",
       "      <td>6304484054</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00295401U6S2UG3RAQSZ</td>\n",
       "      <td>6305182205</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00295401U6S2UG3RAQSZ</td>\n",
       "      <td>B00004W22I</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user        item   timestamp  rating\n",
       "0  A00295401U6S2UG3RAQSZ  0767015533  1353196800       4\n",
       "1  A00295401U6S2UG3RAQSZ  0792838084  1353196800       4\n",
       "2  A00295401U6S2UG3RAQSZ  6304484054  1353196800       4\n",
       "3  A00295401U6S2UG3RAQSZ  6305182205  1353196800       4\n",
       "4  A00295401U6S2UG3RAQSZ  B00004W22I  1353196800       4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['user','timestamp'], ascending=[True,True], inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's map users and items to continuous integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_user_items(df):\n",
    "\n",
    "    dfc = df.copy()\n",
    "    user_mappings = {k:v for v,k in enumerate(dfc.user.unique())}\n",
    "    item_mappings = {k:v for v,k in enumerate(dfc.item.unique())}\n",
    "\n",
    "    user_list = pd.DataFrame.from_dict(user_mappings, orient='index').reset_index()\n",
    "    user_list.columns = ['orig_id', 'remap_id']\n",
    "    item_list = pd.DataFrame.from_dict(item_mappings, orient='index').reset_index()\n",
    "    item_list.columns = ['orig_id', 'remap_id']\n",
    "    user_list.to_csv(DATA_PATH/'user_list.txt', sep=\" \", index=False)\n",
    "    item_list.to_csv(DATA_PATH/'item_list.txt', sep=\" \", index=False)    \n",
    "\n",
    "    dfc['user'] = dfc['user'].map(user_mappings).astype(np.int64)\n",
    "    dfc['item'] = dfc['item'].map(item_mappings).astype(np.int64)\n",
    "        \n",
    "    return user_mappings, item_mappings, dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item   timestamp  rating\n",
       "0     0     0  1353196800       4\n",
       "1     0     1  1353196800       4\n",
       "2     0     2  1353196800       4\n",
       "3     0     3  1353196800       4\n",
       "4     0     4  1353196800       4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mappings, item_mappings, dfm = map_user_items(df)\n",
    "dfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train/Test split Method 1\n",
    "\n",
    "This method is designed to reproduce [Xiang Wang et al. 2019](https://arxiv.org/pdf/1905.08108.pdf) paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfm[['user', 'item']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(df):\n",
    "    keys, values = df.sort_values('user').values.T\n",
    "    ukeys, index = np.unique(keys, True)\n",
    "    arrays = np.split(values, index[1:])\n",
    "    df2 = pd.DataFrame({'user':ukeys, 'item':[list(a) for a in arrays]})\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[6, 7, 8, 9, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[20, 19, 18, 17, 16, 11, 14, 13, 12, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[25, 24, 21, 22, 23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[34, 32, 31, 30, 33, 28, 27, 26, 29]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                      item\n",
       "0     0                        [0, 1, 2, 3, 4, 5]\n",
       "1     1                          [6, 7, 8, 9, 10]\n",
       "2     2  [20, 19, 18, 17, 16, 11, 14, 13, 12, 15]\n",
       "3     3                      [25, 24, 21, 22, 23]\n",
       "4     4      [34, 32, 31, 30, 33, 28, 27, 26, 29]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df = f(df1)\n",
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split strategy we will follow is: 80% training, 20% testing. \n",
    "\n",
    "Then, 10% of the training we'll be as validation to tune parameters. Once tuned, one would merge train+validation and re-train with the best performing params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(u, i_l, p=0.8):\n",
    "    s = np.floor(len(i_l)*p).astype('int')\n",
    "    train = list(np.random.choice(i_l, s, replace=False))\n",
    "    test  = list(np.setdiff1d(i_l, train))\n",
    "    return ([u]+train, [u]+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interactions_l = [train_test_split(r['user'], r['item']) for i,r in interactions_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [interactions_l[i][0] for i in range(len(interactions_l))]\n",
    "test =  [interactions_l[i][1] for i in range(len(interactions_l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 3, 0] [0, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "print(train[0], test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take 10% of the train (which was 80%) as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_interactions_l = [train_test_split(t[0], t[1:], p=0.9) for t in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [tr_interactions_l[i][0] for i in range(len(tr_interactions_l))]\n",
    "valid = [tr_interactions_l[i][1] for i in range(len(tr_interactions_l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 7, 8, 10] [1, 6] [1, 9]\n"
     ]
    }
   ],
   "source": [
    "print(train[1], valid[1], test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(min([len(t[1:]) for t in test]), min([len(v[1:]) for v in valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = DATA_PATH/'train.txt'\n",
    "valid_fname = DATA_PATH/'valid.txt'\n",
    "test_fname = DATA_PATH/'test.txt'\n",
    "\n",
    "with open(train_fname, 'w') as trf, open(valid_fname, 'w') as vaf, open(test_fname, 'w') as tef:\n",
    "    trwrt = csv.writer(trf, delimiter=' ')\n",
    "    vawrt = csv.writer(vaf, delimiter=' ')\n",
    "    tewrt = csv.writer(tef, delimiter=' ')\n",
    "    trwrt.writerows(train)\n",
    "    vawrt.writerows(valid)\n",
    "    tewrt.writerows(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split Method 2\n",
    "\n",
    "Based on the code [here](https://github.com/sh0416/bpr/blob/master/preprocess.py).\n",
    "\n",
    "Let's start from the top since we need the `timestamp` column for this approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1353196800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item   timestamp  rating\n",
       "0     0     0  1353196800       4\n",
       "1     0     1  1353196800       4\n",
       "2     0     2  1353196800       4\n",
       "3     0     3  1353196800       4\n",
       "4     0     4  1353196800       4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_size = len(dfm['user'].unique())\n",
    "item_size = len(dfm['item'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_list(df, user_size):\n",
    "    user_list = [dict() for u in range(user_size)]\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        # this could be .append()\n",
    "        user_list[row['user']][row['item']] = row['timestamp']\n",
    "    return user_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a list of dictionaries, one per user, where the keys are the item_ids and the values are the corresponding `timestamps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1697533/1697533 [03:35<00:00, 7884.81it/s]\n"
     ]
    }
   ],
   "source": [
    "total_user_list = create_user_list(dfm, user_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to two users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1353196800, 1: 1353196800, 2: 1353196800, 3: 1353196800, 4: 1353196800, 5: 1353628800}\n",
      "{8660: 1262822400, 9104: 1361923200, 9105: 1362009600, 9106: 1383696000, 9107: 1403136000}\n"
     ]
    }
   ],
   "source": [
    "print(total_user_list[0])\n",
    "print(total_user_list[950])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will split train and test following 2 approaches. \n",
    "\n",
    "1. Train with the 1st n-1 items and test with the most recent item. In this scenario, one would apply this approach to the train dataset as well for validation/tunning. The merge train+validation and re-train again with the best performing params \n",
    "2. Split at random. As before, one has perform hyperparameter optimisation, we could merge train and validation, re-train and test on the \"un-touched\" test dataset\n",
    "\n",
    "The function can take a list of dictionaries where the values are the corresponding `timestamsp` or simply a list. In the later case, the list is assumed to be sorted in increasing timestamp order, so that the most recent interaction is the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(user_list, p=0.8, time_order=False):\n",
    "\n",
    "    train_user_list = [None] * len(user_list)\n",
    "    test_user_list  = [None] * len(user_list)\n",
    "\n",
    "    for user, item_list in enumerate(user_list):\n",
    "        if time_order:\n",
    "            # Choose latest item\n",
    "            if isinstance(item_list, dict):\n",
    "                # if dict, sort by timestamp\n",
    "                items = [i[0] for i in sorted(item_list.items(), key=lambda x: x[1])]\n",
    "                test_user_list[user]  = items[-1]\n",
    "                train_user_list[user] = items[:-1]\n",
    "            elif isinstance(item_list, (list, np.ndarray)):\n",
    "                print('I assume \"user_list\" is sorted with the most recent item being the last one.')\n",
    "                test_user_list[user]  = item_list[-1]\n",
    "                train_user_list[user] = item_list[:-1]\n",
    "        else:\n",
    "            # Random select\n",
    "            if isinstance(item_list, dict):\n",
    "                items =list(item_list.keys())\n",
    "                sz = np.floor(len(items)*p).astype('int')\n",
    "                train_user_list[user] = np.random.choice(items, sz, replace=False)\n",
    "                test_user_list[user] = np.setdiff1d(items, train_user_list[user])\n",
    "            elif isinstance(item_list, (list, np.ndarray)):\n",
    "                sz = np.floor(len(item_list)*p).astype('int')\n",
    "                train_user_list[user] = np.random.choice(item_list, sz, replace=False)\n",
    "                test_user_list[user] = np.setdiff1d(item_list, train_user_list[user])                \n",
    "\n",
    "    return train_user_list, test_user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_list, test_user_list = split_train_test(total_user_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 5, 1, 2]), array([10]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_list[0], test_user_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat the process for train/valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_list, valid_user_list = split_train_test(train_user_list, p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 4, 2]), array([5]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_list[0], valid_user_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pair(user_list):\n",
    "    pair = []\n",
    "    for user, item_set in enumerate(user_list):\n",
    "        pair.extend([(user, item) for item in item_set])\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair = create_pair(train_user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 4),\n",
       " (0, 2),\n",
       " (1, 9),\n",
       " (1, 6),\n",
       " (1, 7),\n",
       " (2, 13),\n",
       " (2, 18),\n",
       " (2, 20),\n",
       " (2, 12)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pair[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save all the information we need for this method in sparse matrices. Given the fact that I took part of this code from [this repo](https://github.com/sh0416/bpr/blob/master/preprocess.py), I am going to honour their naming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sp_mtx(dataset, rows, columns):\n",
    "    R = sp.dok_matrix((user_size, item_size), dtype=np.float32) \n",
    "    for u, itemset in enumerate(dataset):\n",
    "        for i in itemset:\n",
    "            R[u, i] = 1\n",
    "    return R.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w = fill_sp_mtx(train_user_list, user_size, item_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<123960x50052 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1121051 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_w = fill_sp_mtx(valid_user_list, user_size, item_size)\n",
    "test_w = fill_sp_mtx(test_user_list, user_size, item_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<123960x50052 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 191075 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<123960x50052 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 385407 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(DATA_PATH/\"amazon_movies.npz\", train_w=train_w, valid_w=valid_w, test_w=test_w, \n",
    "         train_pair=train_pair, n_users=user_size, n_items=item_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
